<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Celery常见问题]]></title>
    <url>%2FCelery_FAQ_4_1_Stable.html</url>
    <content type="text"><![CDATA[译文出处http://docs.celeryproject.org/en/latest/faq.html This document describes the current stable version of Celery (4.1). 本文长期更新地址： Celery4.1常见问题 术语翻译对照 英文 中文 celery celery worker worker queue 队列 message 消息 task 任务 常规应该用Celery来处理什么样的事情？答案：Queue everything and delight everyone (我的译文参见)解释了为什么你会需要在web的上下文中使用队列。 这里是一些普遍的使用案例： 在后台运行。例如For example, to finish the web request as soon as possible, then update the users page incrementally. This gives the user the impression of good performance and “snappiness”, even though the real work might actually take some time. 在web请求结束后运行 通过异步执行和重试，确保一些事情完成了 制定周期任务 以及一定程度上： 分布式计算 并行执行 误解Celery真的有50000行代码吗？答案：没有。这个和类似的庞大数字在各种场合经常被报道。 核心：7141行代码 测试：14209行 后端，贡献，兼容性代码：9032行 代码行数不是有用的度量标准，因此，即便Celery真的有50K行代码，你也不能从这个数字中得到任何结论。 Celery有很多依赖吗？一个普遍的批评是说Celery使用了太多的依赖。这种担忧背后的原理很难想象，特别是考虑到代码复用在现代软件开发中已经作为成熟的解决复杂性的方式，而且在使用诸如pip和PyPI包管理工具后引入依赖的开销非常低——安装和维护依赖的麻烦已经成为过去式了。 一路上，Celery替换了一些依赖，现在的依赖列表如下： celery kombuKombu是Celery生态系统的一部分，是用来发送和接收messages的库。也是使得Celery支持如此多不同的message brokers的库。Kombu也被用在OpenStack项目中，和其他许多项目中，验证了将其从Celery基础代码中分割出来的选择是有效的。 billiardbilliard是Python多进程模块的一个分叉fork，包含了许多性能和稳定性改善。有一天这些改善最终将会被合并到Python中。 billiard也被用来处理没有多进程模块的老版本python的兼容问题。 pytz提供时区定义和相关工具。kombuKombu依赖于下面的包： amqp 纯Python实现的amqp客户端。AMQP作为默认broker是很自然的依赖。 Note:为了解决流行的配置选择的依赖，Celery定义了许多“bundle”包（捆绑安装^_^）。详见 Celery是heavy-weight，很重的吗？Celery在内存足迹（memory footprint）和性能上造成了非常轻微的开销。但是请注意，默认配置并未在时间或空间上进行优化，优化。 Celery依赖于pickle（序列化库）吗？答案：不，Celery可以支持任何序列化策略。我们內建支持JSON、YAML、Pickle和msgpack。每个任务都和一种content type挂钩，因此你甚至可以一个任务用pickle，另一个用JSON。默认的序列化支持是pickle，但是从4.0版本起，是JSON。如果你需要发送复杂的Python对象作为任务参数，你可以使用pickle作为序列化格式，但是需要注意Notes in Serializers。 如果你需要和其他语言通信，你应该使用合适于任务的序列化格式，通常意味着不能用pickle了。你可以设置一个全局的默认序列化器serializer，默认的serializer用于特定的任务，或者发送单个任务 instance的时候决定用什么serializer。 Celery只支持Django吗？答案：不。 我必须使用AMQP/RabbitMQ吗？答案：不，尽管使用RabbitMQ是推荐的，你也可以使用Redis，SQS，或者Qpid。更多参见broker Redis作为broker表现不如AMQP，但是RabbitMQ作为broker，Redis作为结果存储的组合方式很常用。如果你有严格的可靠性要求，最好使用RabbitMQ，或者其他AMQP broker。一些transports也用轮询（polling），因此他们可能会消耗更多的资源。但是，如果你因为某些原因不能使用AMQP，可以放心使用这些替代品，在大部分场景下都能工作良好，而且以上不是为Celery量身定制的。如果你之前使用Redis/database作为队列也工作得很好，那现在也能。你一直可以到需要的时候再升级。 Celery是多语言的吗？答案：是。worker是用Python实现的。如果某门语言有AMQP客户端，那用这门语言创建一个worker不需要做太多事情。一个Celery的worker只是一个连接broker来处理messages的程序。 而且，有另一种方式来做到语言独立，就是用REST的任务，这样你的任务就不是函数而是url了。有这个信息，你甚至可以创建一个简单的web服务器开启代码预加载。简单地暴露一个表现一个操作的端点endpoint，再创建一个任务，这个任务只是将一个HTTP请求表现给那个端点。 解决问题MySQL抛出死锁错误，怎么办？答案：MySQL有默认的隔离级别设置为REPEATABLE-READ（可重复读），如果你并不真正需要它，可以设置为READ-COMMITTED（读提交）。你可以通过在my.cnf中加入：12[mysqld]transaction-isolation = READ-COMMMITTED 更多有关InnoDB的事务模型，参见MySQL - The InnoDB Transaction Model and Locking . worker什么都不做，hanging挂起了答案：参见MySQL死锁，或者 Task.delay 任务结果返回不可靠答案：如果你使用数据库后端存储结果，特别是MySQL，可能是死锁。参见上上个问题。 为什么Task.delay/apply*这些调用之后worker只是挂起？答案： 一些AMQP客户端有一个bug，如果当前用户无法认证、密码不匹配或者用户没有访问指定虚拟主机的权限，就会挂起。检查broker的日志（RabbitMQ的在/var/log/rabbitmq/rabbit.log），通常会有消息描述原因。 兼容FreeBSD系统吗？答案：看情况。When using the RabbitMQ (AMQP) and Redis transports it should work out of the box. For other transports the compatibility prefork pool is used and requires a working POSIX semaphore implementation, this is enabled in FreeBSD by default since FreeBSD 8.x. For older version of FreeBSD, you have to enable POSIX semaphores in the kernel and manually recompile billiard. Luckily, Viktor Petersson has written a tutorial to get you started with Celery on FreeBSD here: http://www.playingwithwire.com/2009/10/how-to-get-celeryd-to-work-on-freebsd/ 遇到了完整性错误(IntegrityError)：Duplicate Key errors，什么原因？答案：MySQL死锁。 我的任务为什么没有被处理？答案：用RabbitMQ的话，你可以通过运行如下命令看有多少个消费者当前在接收任务：123$ rabbitmqctl list_queues -p &lt;myvhost&gt; name messages consumersListing queues ...celery 2891 2 以上输出表明任务-队列里有2891条messages在等待被处理，而且有两个消费者正在处理他们。 队列从未被清空的一个原因可能是你有一个过期的worker进程劫持了这些messages。如果这个worker没有被正确地杀掉，就有可能发生这种情况。 当一个message被一个worker接收到了，这个worker在标记该message被处理前会等待被应答。这个worker不会重发message给另一个消费者，直到该消费者被正确地关闭。如果你遇到这个问题，你必须手动杀掉所有的worker并重启：1234$ pkill 'celery worker'$ # - If you don't have pkill use:$ # ps auxww | grep 'celery worker' | awk '&#123;print $2&#125;' | xargs kill 你可能必须等一会儿，知道所有的worker都结束了正在执行的任务。如果仍然长时间挂起，你可以强制杀掉：1234$ pkill -9 'celery worker'$ # - If you don't have pkill use:$ # ps auxww | grep 'celery worker' | awk '&#123;print $2&#125;' | xargs kill -9 我的任务为什么不会运行？答案：可能有语法错误导致任务模块没有被导入。你可以看看通过手动执行任务，Celery能不能运行该任务：12&gt;&gt;&gt; from myapp.tasks import MyPeriodicTask&gt;&gt;&gt; MyPeriodicTask.delay() 观察worker的日志文件，是否可以找到该任务，或者有没有其他错误发生。 我的定时任务为什么不会运行？答案：参见上一个问题。 我怎么清理所有的等待中任务？答案：你可以使用celery purge命令来清理所有的已配置的任务队列。1$ celery -A proj purge 或者在代码中：123&gt;&gt;&gt; from proj.celery import app&gt;&gt;&gt; app.control.purge()1753 如果你只是想清理特定队列中的消息，你必须使用AMQP API，或者celery amqp的功能：1$ celery -A proj amqp queue.purge &lt;queue name&gt; 1753是被清理的消息数。 你也可以开启--purge选项去启动worker，worker启动的时候就会清理消息。 我清理了message，但是队列队列中仍然有消息残留？答案：只要任务真的被执行了，任务就被应答（从队列中移除）了。在worker接收到一个任务之后，在真正被执行前需要一点时间，特别是如果有大量任务已经在等待执行。没有被应答的消息，会被worker保持，直到消息关闭和broker（AMQP服务器）的连接。当连接关闭时（比如，因为worker停止了），任务会被broker重发给下一个可用的worker（或者在worker重启后又发给它），因此正确地清理等待任务的队列需要停掉所有的worker，然后再用celery.control.purge清理任务。 结果如果我有一个id指向一个任务，怎么得到任务结果？答案：用task.AsyncResult。12&gt;&gt;&gt; result = my_task.AsyncResult(task_id)&gt;&gt;&gt; result.get() 这会用任务的当前结果后端(result backend)返回一个AsyncResult的实例。如果你需要指定一个自定义的结果后端，或者你想使用当前应用的默认后端，你可以使用app.AsyncResult:12&gt;&gt;&gt; result = app.AsyncResult(task_id)&gt;&gt;&gt; result.get() 安全使用pickle不是有安全隐患吗？答案：事实上，自从Celery4.0起，默认的序列化器是现在的JSON，就确保了人们有意识地选择序列化器并且意识到了这一担忧。防范未认证授权的worker、数据库和其他传输pickled数据的服务接入是必要的。注意到这不仅仅是你应该意识到有关Celery的问题，例如Django也使用pickle作为其缓存客户端。对任务消息，你可以设置task_serializer为json或者yaml，而不是pickle。类似地可以设置result_serializer。 message是否可以加密？答案：一些AMQPworker支持使用SSL（包括RabbitMQ），你可以通过broker_use_ssl开启这一功能。给消息加入额外的加密和安全性也是可能的，如果你有需求，应该联系邮件列表。 以root用户运行worker是安全的吗？答案：不是！我们现在还没有发觉任何安全问题，但是认为安全问题不存在就太天真了，因此推荐以非特权用户运行Celery服务（celery woker， celery beat， celeryev等）。 Brokers为什么RabbitMQ崩溃了？答案：RabbitMQ如果用光内存就会崩溃。未来版本的RabbitMQ会修复这一个问题。https://www.rabbitmq.com/faq.html#node-runs-out-of-memory 注意：这已经不再是问题，RabbitMQ2.0+包含了一个新的固件，对内存不足错误是容忍的。因此推荐RabbitMQ2.1+版本配合Celery使用。如果你还在使用老版本，而且还遇到崩溃问题，赶紧升级吧。 Celery的错误配置最终也会导致老版本RabbitMQ的崩溃。即便不崩溃，也会消耗大量的资源，因此意识到这一普遍陷阱很重要。 事件Events加上-E选项运行worker将会在worker内部事件发生时发送消息。事件应该只在你有一个活跃的监控器消费事件的时候才被开启，否则你需要定期清理事件队列。 AMQP 后端结果在使用AMQP结果后端运行的时候，每个任务结果都会作为消息发送。如果你不收集collect这些结果，他们会积累，RabbitMQ最终会耗尽内存。结果后端现在被弃用了，所以你不应该再使用。如果你需要多个消费者访问结果，可以用RPC后端来做rpc风格的调用，或者一个持久化的后端。默认情况下结果在一天后失效。可以通过配置result_expires来降低这个有效期。 如果你不需要任务结果，确保你设置了ignore_result选项。123456@app.task(ignore_result=True)def mytask(): passclass MyTask(Task): ignore_result = True Celery可以和ActiveMQ/STOMP一起使用吗？答案：不能。 不使用AMQP broker时，哪些特征不支持了？不完全列表： 远程控制命令（仅由Redis支持） 事件监控在所有的虚拟传输中可能不会工作 header和fanout（扇出，Redis支持） exchange types 任务调用tasks时如何复用连接？答案：查看broker_pool_limit设置。v2.5+就默认开启连接池了。 子进程中sudo反回了None有一个sudo的配置选项来使得不经过tty运行sudo的处理是非法的。1Defaults requiretty 如果你在/etc/sudoers文件中有这项配置，那worker作为守护进程跑的时候，任务将不能调用sudo。如果你想开启，你需要移除上面那一行。http://timelordz.com/wiki/Apache_Sudo_Commands 为什么workers不能处理任务的时候还能将任务从队列中删除？答案：worker拒绝未知任务、错误编码的消息、不包含正确域field的消息（按照任务消息协议）。如果不拒绝这些，会导致重复传送，引发死循环。最近版本的RabbitMQ有能力配置一个dead-letter队列来交换，所以那些被拒的消息就被转移到了那里。 我可以通过任务名称调用任务吗？答案：是的，用app.send_task。你也可以在任何语言中使用AMQP客户端通过名字调用一个任务：12&gt;&gt;&gt; app.send_task('tasks.add', args=[2, 2], kwargs=&#123;&#125;)&lt;AsyncResult: 373550e8-b9a0-4666-bc61-ace01fa4f91d&gt; 我能设置当前任务的id吗？答案：是的，当前id以及更多内容在任务请求里都是可用的。123@app.task(bind=True)def mytask(self): cache.set(self.request.id, "Running") Task Request如果你没有任务实例的引用，你可以使用app.current_task：1&gt;&gt;&gt; app.current_task.request.id 但是需要注意，这可能是任何任务，一个被worker执行的任务，或者一个直接被任务调用的任务，或者一个急切eager调用的任务。（此处原文：But note that this will be any task, be it one executed by the worker, or a task called directly by that task, or a task called eagerly.） 可以用current_worker_task得到特定的当前被执行的任务：1&gt;&gt;&gt; app.current_worker_task.request.id 需要注意current_task, 和 current_worker_task 可能是None。 我如何指定一个自定义的task_id？答案：能。1&gt;&gt;&gt; task.apply_async(args, kwargs, task_id='…') 任务上可以使用装饰器吗？答案：能，但需要注意 Basics的侧边栏 我能使用自然数作为task ids吗？答案：能。但是确保其是唯一的，因为两个相同id的任务的行为是未定义的。 我能指定，一旦另一个task结束，马上运行一个task吗？答案：能。你可以在一个任务里面安全地启动一个任务。一个常用的模式是给任务加上回调：1234567891011from celery.utils.log import get_task_loggerlogger = get_task_logger(__name__)@app.taskdef add(x, y): return x + y@app.task(ignore_result=True)def log_result(result): logger.info("log_result got: %r", result) 调用：1&gt;&gt;&gt; (add.s(2, 2) | log_result.s()).delay() 获取更多信息：Canvas: Designing Work-flows 我能取消任务的执行吗？答案：能。用result.revoke():12&gt;&gt;&gt; result = add.apply_async(args=[2, 2], countdown=120)&gt;&gt;&gt; result.revoke() 或者，只有任务id时：12&gt;&gt;&gt; from proj.celery import app&gt;&gt;&gt; app.control.revoke(task_id) 后者也支持传入任务id列表作为参数。 为什么我的远程控制命令被所有的workers接收到了？答案：为了接收到广播的远程控制命令，每一个worker节点基于其节点名创建了一个唯一的队列名。如果你有超过一个worker的主机名相同，控制命令将会在他们间循环接收。为解决这个问题，你可以用-n参数显式地为每个worker设置节点名：12$ celery -A proj worker -n worker1@%h$ celery -A proj worker -n worker2@%h 这里%h扩展成当前主机名。 我能发送一些任务到限定的一些服务器上吗？答案：是的。你可以使用不同的消息路由拓扑，将任务路由到一个或多个worker上，而且一个worker实例可以绑定到多个队列。Routing Tasks 我能禁掉任务的预取prefetching吗？答案：可能！AMQP的属于prefetch令人疑惑，因为它只被用来描述任务预取限制(task prefetching limit)。没有涉及实际的预取。禁掉预取限制是可能的，但是那意味着worker会消费尽可能快地消费尽可能多的任务。一个有关预取限制的讨论，和worker的配置设定:同一时间只预定一个任务 我可以在运行时改变周期任务的间隔时间吗？答案：可以。你可以使用Django的数据库调度器，或者你可以创建一个新的调度子类，覆写is_due():123456from celery.schedules import scheduleclass my_schedule(schedule): def is_due(self, last_run_at): return run_now, next_time_to_check Celery支持task优先级吗？答案：是的， RabbitMQv3.5.0+就支持优先级，Redis传输仿真实现了优先级支持。你也可以通过将高优先级任务路由到不同的worker中，从而把工作优先级排好。在真实世界中，这通常比每一个消息的优先级更为奏效。你可以使用速率限制（rate limiting）和单条消息优先级（per message priorities）的组合来实现响应式的系统。 我应该使用重试retry还是acks_late？答案：看情况。用一个或者另一个都不是必要的，你可能想要使用两个。Task.retry用来重试任务，这是可以用try语句catch到可预知的错误（expected errors）的。AMQP事务不是用来处理这些错误的：如果任务引发了异常，仍然会被应答！ 如果某些原因worker在执行中挂掉了，你需要任务再次执行时，可以使用acks_late设置。没人知道worker挂掉了，这很重要，如果知道worker挂掉，通常有不可恢复的错误，需要人工介入（worker或者任务代码的bug）。理想情况下，你可以安全地重试任何失败的任务，但是有少数情况例外，假设有如下任务：12345def process_upload(filename, tmpfile): # Increment a file count stored in a database increment_file_counter() add_file_metadata_to_db(filename, tmpfile) copy_file_to_destination(filename, tmpfile) 如果它在拷贝文件时挂掉了，我们会知道这里有个未完成状态存在。这不是个严格的教学场景，但你大概可以想象一些更为灾难性的场景。目前为止，编程较少的话则可靠性更弱。默认值是好的，需要它并且知道它们在干什么的用户仍然能开启acks_late（未来希望使用手动应答）。此外，Task.retry在AMQP事务中有不可用的特性：在重试中延迟，最大重试次数等。因此，可以对Python中的错误使用重试，如果你的任务是幂等的而且要求可靠性级别，结合acks_late一起使用。 我可以计划让tasks在特定的时间执行吗？答案：可以。使用Task.apply_async()的eta参数。周期任务 我可以安全地关闭worker吗？答案：是的，使用TERM信号。这会告诉worker去结束所有当前执行的作业，然后尽可能快地关闭。只要完全关闭，实验性的传输中也不应该会有任务丢失。你决不应该通过KILL信号(kill -9)来停止worker，除非你试过几次TERM等了几分钟看有没有关闭。 另外，确保你只是杀掉了worker的主进程，而不是它的任何子进程。如果你知道关闭worker所依赖的一个子进程正在执行一个任务，你可以给这个特定的子进程指定一个杀死信号（kill signal），这也意味着任务会被设定一个WorkerLostError状态，因此这个任务不会再执行了。 如果你安装了setproctitle模块，指定进程类型很容易。1$ pip install setproctitle 安装这个库，你可以看到在ps命令的列表中看到进程类型，但是worker必须重启才能生效。 停止worker 我可以在平台的后端运行worker吗？Answer: Yes, please see [Daemonization[(http://docs.celeryproject.org/en/latest/userguide/daemonizing.html#daemonizing. Djangodjango-celery-beat创建的数据库表有什么目的？用到数据库后端定时器（database-backend schedule）的时候，从PeriodicTask的数据模型中取出周期任务计划有一些其他的辅助表 (IntervalSchedule, CrontabSchedule, PeriodicTasks)。 django-celery-results创建的数据库表有什么目的？Django的数据库结果后端扩展需要两个额外的数据模型：TaskResult and GroupResult. WindowsCelery支持Windows吗？答案：不。4.x版本以上就不支持Windows了。 欢迎扫码加群交流 常见问题目录 常规 应该用Celery来处理什么样的事情？ 一些误解 Celery真的有50000行代码吗？ Celery有很多依赖吗？ celery kombu Celery是heavy-weight，很重的吗？ Celery依赖于pickle（序列化库）吗？ Celery只支持Django吗？ 我必须使用AMQP/RabbitMQ吗？ Celery是多语言的吗？ 解决问题 MySQL抛出死锁错误，怎么办？ worker什么都不做，hanging挂起了 任务结果返回不可靠 为什么task.delay/apply*这些调用之后worker只是挂起？ 兼容FreeBSD系统吗？ 遇到了完整性错误(IntegrityError)：Duplicate Key errors，什么原因？ 我的任务为什么没有被处理？ 我的任务为什么不会运行？ 我的定时任务为什么不会运行？ 我应该清理所有的等待中任务吗？ 我怎么清理所有的等待中任务？ 我清理了消息，但是队列中仍然有消息残留？ 结果 如果我有一个id指向一个任务，怎么得到任务结果？ 安全 使用pickle不是有安全隐患吗？ message是否可以加密？ 以root用户运行worker是安全的吗？ Brokers 为什么RabbitMQ崩溃了？ Celery可以和ActiveMQ/STOMP一起使用吗？ 不使用AMQP broker时，哪些特征不支持了？ Tasks 调用任务时如何复用连接？ 子进程中sudo反回了None 为什么workers不能处理任务的时候还能将任务从队列中删除？ 我可以通过任务名称调用任务吗？ 我如何获得当前任务的id？ 我如何指定一个自定义的任务_id？ 任务上可以使用装饰器吗？ 我能使用自然数作为任务 ids吗？ 我能指定，一旦另一个任务结束，马上运行一个任务吗？ 我能取消任务的执行吗？ 为什么我的远程控制命令被所有的workers接收到了？ 我能发送一些任务到限定的一些服务器上吗？ 我能禁掉任务的预取prefetching吗？ Celery支持任务优先级吗？ 我应该使用重试retry还是acks_late？ 我可以计划让任务在特定的时间执行吗？ 我可以安全地关闭worker吗？ 我可以在平台的后端运行worker吗？ Django django-celery-beat创建的数据库表有什么目的？ django-celery-results创建的数据库表有什么目的？ Windows Celery支持Windows吗？]]></content>
      <categories>
        <category>翻译</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F%E5%A4%A7%E9%B1%BC%E6%B5%B7%E6%A3%A0%E5%BD%B1%E8%AF%84.html</url>
    <content type="text"><![CDATA[鱼塘末日—— 《大鱼海棠》标签（空格分隔）：影评 “美术的皮囊是要为故事整体做嫁衣的。”很可惜《大鱼海棠》没有。 先说为什么选这部电影写影评。我没有在12年前就听说过电影主创人员的梦想，我甚至在拿到电影票之前从未听说过这部电影。而电影票，也就是在一个无聊的下午，室友问我，手里有两张免费电影票，要不要一起去。所以我一开始就不存在期望这东西。电影看得很开心。嗯，画面让我恍然想起宫崎骏，尤其是外景，还是颤抖的旁白音以及老奶奶，背景音乐也不错。电影放完还有那两位导演过来讲他们的故事。导演说他是清华的工科生。哟，厉害厉害，我辈楷模。导演说他做了十二年的梦。哟，厉害厉害，能睡这么久不简单呐。故事呢？我记得导演说，打麻将那个场景，麻将的特写是要告诉女主三思而后行。有趣。过几天电影正式上映，网上一逛，骂声一片。我想导演十二年的梦终于要醒了。更加有趣了。 跟风骂几句。 男主脱光竟然木有小鸡鸡？凭什么导演你有不让人家有？ 女主真绿茶，人家为了您的幸福甘愿去死，没想到一直被当哥哥。 男主你说你除了故事一开始救了一条鱼，还干了啥？ 女主应该以类似“反人类罪”的罪行被判罚吧？编剧的价值观呢？噢不对，编剧确定不是在划水？ 庄子北冥有鱼的鱼，怎么那么小？说好的几千里呢？ 那个老年旁白还能更无耻些吗？活了这么久怎么三观还是崩塌的？ 中国风就是引出题名的“大鱼”，以及“鱼”的住所福建土楼？两千年的儒家思想呢？ 三角恋玩得真不溜，比偶像剧差远了。 扯犊子情怀，国漫崛起新希望这名字好玩？ 强行转3D，无耻圈钱。 终于凑齐十大罪状。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2FWorkers%20on%20tap%E3%80%90The%20Economist%20Jan%203rd%202015%E3%80%91.html</url>
    <content type="text"><![CDATA[The rise ofthe on-demand economyposes diﬃcult questions forworkers, companies and politicians I N THE early 20th centuryHenryFord combined moving assembly lines with mass labour to make building carsmuch cheaper and quicker—thus turning the automobile from a rich man’s toy into trans-port for the masses. Today a growing group of entrepreneurs is striving to do the same to services, bringing together computer power with freelance workers to supply luxuries that were once reserved for the wealthy. Uber provides chauﬀeurs. Handy supplies cleaners. SpoonRocket delivers restaurant meals to your door. Instacart keeps your fridge stocked. In San Francisco a young computer programmer can already live like a princess. Yet this on-demand economy goes much widerthan the oc- casional luxury. Click on Medicast’s app, and a doctor will be knocking on your door within two hours. Want a lawyer or a consultant? Axiom will supply the former, Eden McCallum the latter. Other companies oﬀer prizes to freelances to solve R&amp;D problems or to come up with advertising ideas. And a growing number of agencies are delivering freelances of all sorts, such as Freelancer.com and Elance-oDesk, which links up 9.3m workers for hire with 3.7m companies. The on-demand economy is small, but it is growing quickly(see pages17-20). Uber, founded in San Francisco in 2009, nowoperates in 53 countries, had sales exceeding $1 billion in 2014and a valuation of $40 billion. Like the moving assembly line,the idea of connecting people with freelances to solve theirproblems sounds simple. But, like mass production, it has pro-found implications for everything from the organisation ofworkto the nature ofthe social contract in a capitalist society. Baby, you can drive my car—and stockmy fridgeSome of the forces behind the on-demand economy havebeen around for decades. Ever since the 1970s the economythat Henry Ford helped create, with big ﬁrms and big trade un-ions, has withered. Manufacturing jobs have been automatedout of existence or outsourced abroad, while big companieshave abandoned lifetime employment. Some 53m Americanworkers already workas freelances. But two powerful forces are speedingthis up and pushing itinto ever more parts of the economy. The ﬁrst is technology.Cheap computing power means a lone thespian with an Ap-ple Mac can create videos that rival those of Hollywood stu-dios. Complextasks, such as programminga computeror writ-ing a legal brief, can now be divided into their componentparts—and subcontracted to specialists around the world. Theon-demand economy allows society to tap into its under-usedresources: thus Uber gets people to rent their own cars, and In-noCentive lets them rent their spare brain capacity. The other great force is changing social habits. Karl Marxsaid that the world would be divided into people who ownedthe means of production—the idle rich—and people whoworked for them. In fact it is increasingly being divided be-tween people who have money but no time and people whohave time but no money. The on-demand economy provides away for these two groups to trade with each other. This will push service companies to follow manufacturersand focus on their core competencies. The “transaction cost”of using an outsider to ﬁx something (as opposed to keepingthatfunction within yourcompany) isfalling. Rather than con-trolling ﬁxed resources, on-demand companies are middle-men, arranging connections and overseeing quality. Theydon’t employ full-time lawyers and accountants with guaran-teed pay and beneﬁts. Uber drivers get paid only when theywork and are responsible for their own pensions and healthcare. Risksborne bycompaniesare beingpushed backon to in-dividuals—and that has consequences for everybody. Obamacare and Brand YouThe on-demand economy is already provoking political de-bate, with Uber at the centre of much of it. Many cities, statesand countries have banned the ride-sharing company on safe-ty or regulatory grounds. Taxi drivers have staged protestsagainst it. Uber drivers have gone on strike, demanding betterbeneﬁts. Techno-optimists dismiss all this as teething trouble:the on-demand economygivesconsumersgreaterchoice, theyargue, while letting people workwhenever they want. Societygains because idle resources are put to use. Most ofUber’s carswould otherwise be parked in the garage. The truth is more nuanced. Consumers are clear winners;so are Western workers who value ﬂexibility over security,such as women who want to combine work with child-rear-ing. Taxpayers stand to gain ifon-demand labouris used to im-prove eﬃciency in the provision of public services. But work-ers who value security over ﬂexibility, including a lot ofmiddle-aged lawyers, doctors and taxi drivers, feel justiﬁablythreatened. And the on-demand economy certainly producesunfairnesses: taxpayers will also end up supporting manycontract workers who have never built up pensions. This sense of nuance should inform policymaking. Gov-ernments that outlaw on-demand ﬁrms are simply handicap-ping the rest of their economies. But that does not mean theyshould siton theirhands. The waysgovernmentsmeasure em-ployment and wages will have to change. Many European taxsystems treat freelances as second-class citizens, while Ameri-can stateshave diﬀerentrulesfor“contractworkers” thatcouldbe tidied up. Too much ofthe welfare state isdelivered throughemployers, especially pensions and health care: both shouldbe tied to the individual and made portable, one area whereObamacare was a big step forward. But even ifgovernments adjust theirpolicies to a more indi-vidualistic age, the on-demand economy clearly imposesmore risk on individuals. People will have to master multipleskills if they are to survive in such a world—and keep thoseskills up to date. Professional sorts in big service ﬁrms willhave to take more responsibility for educating themselves.People will also have to learn how to sell themselves, throughpersonal networkingand social media or, ifthey are really am-bitious, turning themselves into brands. In a more ﬂuid world,everybody will need to learn how to manage You Inc.]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2FProduct-Design-Methods.html</url>
    <content type="text"><![CDATA[TAMSwitching CostUCDUTAUTLoyalty DesignGrowth HackingELMTangible Design: 极度易用（小孩易学） 计算智能-感知智能-认知智能-类人智能]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world.html</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[Ext2fsd软件对windows文件系统性能的坑比表现]]></title>
    <url>%2FExt2Fsd.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[中国移动研究院老掌门效力华科大，Dian团队步入新主帅黄晓庆时代]]></title>
    <url>%2F%E9%BB%84%E6%99%93%E5%BA%86.html</url>
    <content type="text"><![CDATA[编者按：黄晓庆，Dian团队导师，达闼科技创始人兼CEO，前中国移动研究院院长，“千人计划”国家特聘专家。1982年毕业于华中科技大学电信系。2017年8月，就任华中科技大学电子信息与通信学院院长。 “人类最重要的使命，就是摆脱太阳系的束缚。”作为星际迷航的铁杆粉丝，黄晓庆几乎每次演讲，都会观宇宙浩荡而天马行空，论科技浪潮而挥斥方遒。这一次也无例外——2017年10月15日晚，已经担任Dian团队7年兼职导师的著名通信和人工智能专家黄晓庆（Bill Huang），以团队新领军的身份，出现在全体队员面前作主旨演讲，到场聆听的还有“点石创校”学员。此次主旨演讲由已退休交棒的Dian团队创始人刘玉老师主持。刘老师回忆，黄晓庆与Dian团队的缘分，要追溯到2010年启明学院落成之时。彼时，喜择交良友的刘玉老师邀请黄晓庆担任Dian团队导师，此后黄晓庆作为兼职导师，给Dian团队带来了诸多资源。刘老师强调，“一个团队的格局是领军的格局决定的，一个团队的高度是领军的高度决定的”，Dian团队的28位顾问，给行路中的Dian团队指明了“绿洲”的方向——创新创业。随后刘玉老师正式宣布，Dian团队导师黄晓庆成为新主帅，邀请其作主旨演讲。全场掌声雷动，经久不息。 这是一个新的时代。所有人都在瞩目着。“科学把我们带到了一个特别重要的历史局面，这就是第四次工业革命，也许是我们人类前所未见的科学的爆发点，就在未来五十年左右。那这个点是什么？我们叫做“奇点”。我们从事信息科学的可能最美妙的一个梦想就是，我们人类有可能在未来三十年到五十年有可能做出在智能水平上达到甚至超过人类的机器。” 黄晓庆对于人工智能引发第四次工业革命的信心，令人印象深刻——而这显然来自于他对科技创新的深刻洞见与卓越的工程实践能力。“创新就是 Unseat the establishment”，“要有一种挑战传统，挑战权威者，挑战主流的勇气”，在美国这叫 “Cowboy Spirit”，也是我们时代最需要的精神。勇气是为其一，其二是要有“能够挑战传统、权威的能力和水平”。而能力，来自于学习，来自于努力。黄晓庆以亲身经历说法，“不懂英语没法搞国际化”，“管理是科学，是人文的物理学。越是被管理的人，越需要知道你是怎么被管理的”，“现在懂TensorFlow，相当于30年前懂Unix和C语言”。谈及Dian团队未来的发展方向，七年前黄晓庆指向了“拥抱移动互联网”，而现在，业已身为达闼科技创始人兼CEO的黄晓庆，则毫不犹豫地选定了人工智能。从图灵到DeepMind，从飞机到神经网络，从生物细胞到计算机网络，黄晓庆化身“科技史学家”、“生物学家”、“计算机科学家”，带领所有听众遨游了人工智能的过去、现在与将来。而无线电通信专业出身的黄晓庆，亦颇有洞见地指出：5G技术将推动人工智能与机器人的发展，云端机器人网络流量将是人类的100倍左右。 1982年，作为“全武汉第一个留美的自费留学生”，黄晓庆只身一人去了美国。1982年6月，黄晓庆成了美国伊利诺斯州立大学研究生院第一个中国大陆来的学生。1997年，黄晓庆在UT斯达康内部创业，想做全世界最伟大的软交换的移动交换机——用IP技术做交换，颠覆贝尔实验室在60、70年代发明的电路交换技术。2007年，黄晓庆被中国移动请回国，担任中国移动研究院院长。2011年，黄晓庆在斯坦福遇到一位教授生物工程系教授，带着某种“上帝视角”的宏观感的架构师出身的他，“顿悟”到云端机器人大脑的可行性——因为网络的延迟，已经逐渐降到了人类感知不到的程度。2015年，达闼科技成立。“既然要做云端机器人，英文就叫Cloudminds。中文“达闼”音译自“Data”。除了‘数据’，它还是《星际迷航》里一个机器人的名字。‘闼’，最开始我也不认识，跑去查字典，发现是‘推门而入’的意思。这个寓意太好了，马到成功。” 做达闼之前，黄晓庆许了一个宏愿。他要做的事，和所有人工智能从业者都不是竞争关系。他心中的局，更像一个行业托举者，瞄准的是未来人机世界的大规则。 达达马蹄，郑愁予听到的是江南烟雨过客，而黄晓庆听到的是服务机器人的脚步声。“水渺茫而法白，山排闼以争前”，而黄晓庆眼中的达闼科技，显然不止于争前，而是要在他人觉前方渺茫不知所向时，引领一时风骚——做云端智能的基础架构。这般使命感，来自于他的相信。“作为人类必须承认：宇宙法则有可能是被设计的。你瞧，一个粒子里面的结构，和一个星系的结构，基本是一样的，多神奇。造物者早把这个东西给搞明白了，他告诉我们世界就是这个样子，你得‘信’。”当然，如果只是相信，黄晓庆或许也只能”用美丽的雪花”，“在凄凉的大地”，“用孩子的笔体”去写下“相信未来”，而不能以一名工程师的身份，用代码造就一个真实的未来。“哲学家认为自己就是上帝，没有必要去讨论别的事；数学家们想反抗上帝；物理学家想学习上帝；生物学家从某种意义上讲想造上帝的反，要摆脱伊甸园……工程师说都不用，我们再造一个。”正是基于类似的理念，15年前，“旨在通过真实项目实践培养学生的创新能力、实践精神和综合素质”的Dian团队才会诞生在喻家山下——因为相信真实项目实践能够培养人，因为真真正正地主动实践着。而2010年与Dian团队结缘的黄晓庆，兴奋，激动，因为“有组织的优秀学生联合在一起创新是一种很了不起的现象”。 2016年9月，刘玉老师带领Dian团队队员前往深圳参加点石论坛，黄晓庆作为Dian团队导师上台演讲，谈宇宙之恢弘，论云端之架构，台下新老队员听得入神，深受启发。论坛上刘玉老师笑称曾邀请黄晓庆担任我校电信学院院长。不承想一语中的。今年八月底，黄晓庆即将就任电信学院院长的消息似平地惊雷，振奋人心。在非正式的就职演说中，黄晓庆提到，“我们要把华科大变成中国的斯坦福”。这一愿景，与刘玉老师的想法不谋而合。而这一愿景，也仰仗于所有Dian团队队员团结协作，夺命狂奔，以不负“有组织的优秀学生联合在一起创新”。战略战术上，黄晓庆提了三点想法。一是成立人工智能交叉科学研究中心（The Cross Science Research Center Of Artificial Intelligence）。黄晓庆强调，“要尽快成立，抢占先机”。二是教育改革。黄晓庆列举了诸如清华施一公、姚期智等几个“标杆”式教改做法，以供考察借鉴。三是拥抱互联网。要借助互联网的力量，邀请世界级的大师网上授课。此次主旨演讲，Dian团队现任队长严子怡在问答环节中第一个向黄晓庆发问：在工程应用领域有着多年积淀的Dian团队，在人工智能时代下如何寻求新的发展之路？黄晓庆表示，如果对深度学习很了解，可以解决很多很重要的问题。他可以为团队提供平台、传感器，甚至机器人。刘玉老师则勉励队员们，应加强自身学习，以应对机会与挑战。 诸葛孔明曾作《出师表》，言“然侍卫之臣不懈于内，忠志之士忘身于外者”。拳拳赤子心，莫如黄晓庆——黄晓庆在接受媒体采访时曾说过：“我2006年决定回国加入中国移动，我很多好朋友说你疯了，凭我对你的了解，你在体制内绝对混不过6个月，要不你被炒鱿鱼，要不你受不了走了，他说你是个自由主义者，独立思考者，又不会拍马屁。可在任何时候，我相信一点：诚心会感动人。我在中国移动，很多人就很包容我，他们说这小子不是瞎忽悠的，他放弃了国外的高薪回来了，每天干这个事儿，每天干到11点，他不是在那里花天酒地，他不是在瞎胡闹。”现如今，黄晓庆以”分身之术“回到母校，“希望在我领导的电信学院之下，所有同仁由我带头，成为我们华中科技大学深化教育改革的急先锋”，此番气魄，尤若要在迷航中向最亮处摸索，在星际中留下浓墨重彩的一道轨迹。此等胸怀，“中国梦”与“奇点梦”交相辉映，是为民族长河中又一波浪潮中的一朵热烈的浪花。而这浪花，由汗水结成——仅此次十月中旬来校，黄晓庆每日刺促不休，会领导见教授，寻经验谈发展。“实干兴邦”，盒饭也香——为了能在有限的时间内更快地进入院长的工作状态，黄晓庆干脆在工作之中就地吃盒饭，十足的创业者姿态！ “一个团队的格局是领军的格局决定的，一个团队的高度是领军的高度决定的”。而这位创业者新主帅，又将带领深耕创新创业的Dian团队，步入怎样的时代？我们期待着。]]></content>
      <categories>
        <category>杂文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Git超简明指南与超常用命令]]></title>
    <url>%2FGit%E8%B6%85%E7%AE%80%E6%98%8E%E6%8C%87%E5%8D%97%E4%B8%8E%E8%B6%85%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[git fetch origin branchname:branchname 可以把远程某各分支拉去到本地的branchname下，如果没有branchname，则会在本地新建branchname git checkout origin/remoteName -b localName 获取远程分支remoteName 到本地新分支localName，并跳到localName分支 git push -u origin local_branch_name git push origin –delete scp username@servername:/path/filename /tmp/local_destination]]></content>
      <categories>
        <category>快速入门快速实践</category>
        <category>一天</category>
        <category>常用</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一天：Kafka入门与项目实战]]></title>
    <url>%2F%E4%B8%80%E5%A4%A9%EF%BC%9AKafka%E5%85%A5%E9%97%A8%E4%B8%8E%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.html</url>
    <content type="text"><![CDATA[前言未完待续。此文将持续更新。 v0.1 [初稿：可运行的代码] 2017-08-25 18:50:08 Quick Start CET4没过轻松读：Apache 官方最新文档 For Pythoner直接看Consumer类源码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196class KafkaConsumer(six.Iterator): """Consume records from a Kafka cluster. The consumer will transparently handle the failure of servers in the Kafka cluster, and adapt as topic-partitions are created or migrate between brokers. It also interacts with the assigned kafka Group Coordinator node to allow multiple consumers to load balance consumption of topics (requires kafka &gt;= 0.9.0.0). The consumer is not thread safe and should not be shared across threads. Arguments: *topics (str): optional list of topics to subscribe to. If not set, call :meth:`~kafka.KafkaConsumer.subscribe` or :meth:`~kafka.KafkaConsumer.assign` before consuming records. Keyword Arguments: bootstrap_servers: 'host[:port]' string (or list of 'host[:port]' strings) that the consumer should contact to bootstrap initial cluster metadata. This does not have to be the full node list. It just needs to have at least one broker that will respond to a Metadata API Request. Default port is 9092. If no servers are specified, will default to localhost:9092. client_id (str): A name for this client. This string is passed in each request to servers and can be used to identify specific server-side log entries that correspond to this client. Also submitted to GroupCoordinator for logging with respect to consumer group administration. Default: 'kafka-python-&#123;version&#125;' group_id (str or None): The name of the consumer group to join for dynamic partition assignment (if enabled), and to use for fetching and committing offsets. If None, auto-partition assignment (via group coordinator) and offset commits are disabled. Default: None key_deserializer (callable): Any callable that takes a raw message key and returns a deserialized key. value_deserializer (callable): Any callable that takes a raw message value and returns a deserialized value. fetch_min_bytes (int): Minimum amount of data the server should return for a fetch request, otherwise wait up to fetch_max_wait_ms for more data to accumulate. Default: 1. fetch_max_wait_ms (int): The maximum amount of time in milliseconds the server will block before answering the fetch request if there isn't sufficient data to immediately satisfy the requirement given by fetch_min_bytes. Default: 500. fetch_max_bytes (int): The maximum amount of data the server should return for a fetch request. This is not an absolute maximum, if the first message in the first non-empty partition of the fetch is larger than this value, the message will still be returned to ensure that the consumer can make progress. NOTE: consumer performs fetches to multiple brokers in parallel so memory usage will depend on the number of brokers containing partitions for the topic. Supported Kafka version &gt;= 0.10.1.0. Default: 52428800 (50 Mb). max_partition_fetch_bytes (int): The maximum amount of data per-partition the server will return. The maximum total memory used for a request = #partitions * max_partition_fetch_bytes. This size must be at least as large as the maximum message size the server allows or else it is possible for the producer to send messages larger than the consumer can fetch. If that happens, the consumer can get stuck trying to fetch a large message on a certain partition. Default: 1048576. request_timeout_ms (int): Client request timeout in milliseconds. Default: 40000. retry_backoff_ms (int): Milliseconds to backoff when retrying on errors. Default: 100. reconnect_backoff_ms (int): The amount of time in milliseconds to wait before attempting to reconnect to a given host. Default: 50. reconnect_backoff_max_ms (int): The maximum amount of time in milliseconds to wait when reconnecting to a broker that has repeatedly failed to connect. If provided, the backoff per host will increase exponentially for each consecutive connection failure, up to this maximum. To avoid connection storms, a randomization factor of 0.2 will be applied to the backoff resulting in a random range between 20% below and 20% above the computed value. Default: 1000. max_in_flight_requests_per_connection (int): Requests are pipelined to kafka brokers up to this number of maximum requests per broker connection. Default: 5. auto_offset_reset (str): A policy for resetting offsets on OffsetOutOfRange errors: 'earliest' will move to the oldest available message, 'latest' will move to the most recent. Any other value will raise the exception. Default: 'latest'. enable_auto_commit (bool): If True , the consumer's offset will be periodically committed in the background. Default: True. auto_commit_interval_ms (int): Number of milliseconds between automatic offset commits, if enable_auto_commit is True. Default: 5000. default_offset_commit_callback (callable): Called as callback(offsets, response) response will be either an Exception or an OffsetCommitResponse struct. This callback can be used to trigger custom actions when a commit request completes. check_crcs (bool): Automatically check the CRC32 of the records consumed. This ensures no on-the-wire or on-disk corruption to the messages occurred. This check adds some overhead, so it may be disabled in cases seeking extreme performance. Default: True metadata_max_age_ms (int): The period of time in milliseconds after which we force a refresh of metadata, even if we haven't seen any partition leadership changes to proactively discover any new brokers or partitions. Default: 300000 partition_assignment_strategy (list): List of objects to use to distribute partition ownership amongst consumer instances when group management is used. Default: [RangePartitionAssignor, RoundRobinPartitionAssignor] heartbeat_interval_ms (int): The expected time in milliseconds between heartbeats to the consumer coordinator when using Kafka's group management feature. Heartbeats are used to ensure that the consumer's session stays active and to facilitate rebalancing when new consumers join or leave the group. The value must be set lower than session_timeout_ms, but typically should be set no higher than 1/3 of that value. It can be adjusted even lower to control the expected time for normal rebalances. Default: 3000 session_timeout_ms (int): The timeout used to detect failures when using Kafka's group management facilities. Default: 30000 max_poll_records (int): The maximum number of records returned in a single call to :meth:`~kafka.KafkaConsumer.poll`. Default: 500 receive_buffer_bytes (int): The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. Default: None (relies on system defaults). The java client defaults to 32768. send_buffer_bytes (int): The size of the TCP send buffer (SO_SNDBUF) to use when sending data. Default: None (relies on system defaults). The java client defaults to 131072. socket_options (list): List of tuple-arguments to socket.setsockopt to apply to broker connection sockets. Default: [(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)] consumer_timeout_ms (int): number of milliseconds to block during message iteration before raising StopIteration (i.e., ending the iterator). Default block forever [float('inf')]. skip_double_compressed_messages (bool): A bug in KafkaProducer &lt;= 1.2.4 caused some messages to be corrupted via double-compression. By default, the fetcher will return these messages as a compressed blob of bytes with a single offset, i.e. how the message was actually published to the cluster. If you prefer to have the fetcher automatically detect corrupt messages and skip them, set this option to True. Default: False. security_protocol (str): Protocol used to communicate with brokers. Valid values are: PLAINTEXT, SSL. Default: PLAINTEXT. ssl_context (ssl.SSLContext): Pre-configured SSLContext for wrapping socket connections. If provided, all other ssl_* configurations will be ignored. Default: None. ssl_check_hostname (bool): Flag to configure whether ssl handshake should verify that the certificate matches the brokers hostname. Default: True. ssl_cafile (str): Optional filename of ca file to use in certificate verification. Default: None. ssl_certfile (str): Optional filename of file in pem format containing the client certificate, as well as any ca certificates needed to establish the certificate's authenticity. Default: None. ssl_keyfile (str): Optional filename containing the client private key. Default: None. ssl_password (str): Optional password to be used when loading the certificate chain. Default: None. ssl_crlfile (str): Optional filename containing the CRL to check for certificate expiration. By default, no CRL check is done. When providing a file, only the leaf certificate will be checked against this CRL. The CRL can only be checked with Python 3.4+ or 2.7.9+. Default: None. api_version (tuple): Specify which Kafka API version to use. If set to None, the client will attempt to infer the broker version by probing various APIs. Different versions enable different functionality. Examples: (0, 9) enables full group coordination features with automatic partition assignment and rebalancing, (0, 8, 2) enables kafka-storage offset commits with manual partition assignment only, (0, 8, 1) enables zookeeper-storage offset commits with manual partition assignment only, (0, 8, 0) enables basic functionality but requires manual partition assignment and offset management. For the full list of supported versions, see KafkaClient.API_VERSIONS. Default: None api_version_auto_timeout_ms (int): number of milliseconds to throw a timeout exception from the constructor when checking the broker api version. Only applies if api_version set to 'auto' metric_reporters (list): A list of classes to use as metrics reporters. Implementing the AbstractMetricsReporter interface allows plugging in classes that will be notified of new metric creation. Default: [] metrics_num_samples (int): The number of samples maintained to compute metrics. Default: 2 metrics_sample_window_ms (int): The maximum age in milliseconds of samples used to compute metrics. Default: 30000 selector (selectors.BaseSelector): Provide a specific selector implementation to use for I/O multiplexing. Default: selectors.DefaultSelector exclude_internal_topics (bool): Whether records from internal topics (such as offsets) should be exposed to the consumer. If set to True the only way to receive records from an internal topic is subscribing to it. Requires 0.10+ Default: True sasl_mechanism (str): String picking sasl mechanism when security_protocol is SASL_PLAINTEXT or SASL_SSL. Currently only PLAIN is supported. Default: None sasl_plain_username (str): Username for sasl PLAIN authentication. Default: None sasl_plain_password (str): Password for sasl PLAIN authentication. Default: None def next(self) def _message_generator(self): HTTP流式响应：https://gist.github.com/CMCDragonkai/6bfade6431e9ffb7fe88 https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html Chrome抓包：chrome://net-internals/#requests Kafka入门：http://www.aboutyun.com/thread-12882-1-1.html 我的业务需求已有实现是pip包客户端从flask服务器获取kafka服务器地址，在客户端直接消费。 需要加上权限认证提升安全性，因此需要交由flask转发kafka日志。 服务端实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# -*- coding: utf-8 -*-from flask_restful import Resource, reqparsefrom flask import Response, jsonify, g, stream_with_contextfrom App.common import error_util as EDfrom App.views.user_views import authfrom kafka import KafkaConsumerimport jsonfrom flask.ctx import _request_ctx_stackfrom itertools import chain@check_api_cost_time@auth.login_required@flask_app.route('/api/v1/logs', methods=['GET'], endpoint='task-logs')def get_logs_of_task(): parser = reqparse.RequestParser() parser.add_argument('method', type=str, location='args') parser.add_argument('id', type=str, location='args') args = parser.parse_args() if args.get('method') and args.get('method').lower() == 'kafka': task_id = args.get('id') if not task_id: return jsonify(ED.error_response_norm(ED.err_req_data)) if not is_owned_by_guser(get_experiment_by_id(task_id)): return jsonify(ED.error_response_norm(ED.err_user_permission)) res = Response(stream_with_context(chain(celery_log_generator(task_id),container_log_generator(task_id))), direct_passthrough=True, mimetype='multipart/x-mixed-replace') # res.headers['Transfer-Encoding'] = 'chunked' return resdef container_log_generator(task_id): consumer = KafkaConsumer(task_id, bootstrap_servers=flask_app.config['KAFKA_BROKER_URI'], auto_offset_reset='earliest', enable_auto_commit=False, request_timeout_ms=40000, consumer_timeout_ms=10000) try: for msg in consumer: str_line = json.loads(msg.value).get("log").strip("\n") + b'\r\n' yield bytes(str_line) except StopIteration as e: returndef celery_log_generator(task_id): path = flask_app.config['UPLOAD_LOG_FOLDER'] + task_id + "/worker.log" with open(path) as f: for line in f: yield line 客户端实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192def logs(id, tail, sleep_duration=1): """ Print the logs of the run. """ # experiment = ExperimentClient().get(id) # task_instance = TaskInstanceClient().get(get_module_task_instance_id(experiment.task_instances)) # log_server = ExperimentClient().get_log_server(id) # if not log_server: # russell_logger.info("There is not a valid task id") # return import logging russell_logger.info("loading log...") logging.disable(sys.maxsize) lines = ExperimentClient().get_log_stream(id) if not lines: print("No logs....") for line in lines: print(line) # consumer = KafkaConsumer(id, bootstrap_servers=log_server, # auto_offset_reset='earliest', enable_auto_commit=False) # for msg in consumer: # print(json.loads(msg.value).get("log").strip("\n")) logging.disable(logging.NOTSET)'''ExperimentClinet(BaseHttpClient''' def get_log_stream(self, id, method='kafka'): timeout = 50 response = self.request("GET", "/logs", params=&#123;'method':method, 'id':id&#125;, stream=True, timeout=timeout) return response.iter_lines()'''BaseHttpClient''' """ Base client for all HTTP operations """class BaseHttpClient(object): def __init__(self): self.base_url = "&#123;&#125;/api/v1".format(host) self.access_token = AuthConfigManager.get_access_token() def request(self, method, url, params=None, data=None, files=None, timeout=5, access_token=None, stream=False): """ Execute the request using requests library """ request_url = self.base_url + url russell_logger.debug("Starting request to url: &#123;&#125; with params: &#123;&#125;, data: &#123;&#125;".format(request_url, params, data)) if access_token: headers = &#123;"Authorization": "Basic &#123;&#125;".format(access_token)&#125; else: headers = &#123;"Authorization": "Basic &#123;&#125;".format( self.access_token.token if self.access_token else None) &#125; try: # print "url: &#123;&#125;".format(request_url) # print "params: &#123;&#125;".format(params) # print "data: &#123;&#125;".format(data) response = requests.request(method, request_url, params=params, headers=headers, data=data, files=files, timeout=timeout, stream=stream) except requests.exceptions.ConnectionError: sys.exit("Cannot connect to the Russell server. Check your internet connection.") if not stream: try: russell_logger.debug("Response Content: &#123;&#125;, Headers: &#123;&#125;".format(response.json(), response.headers)) except Exception: russell_logger.debug("Request failed. Response: &#123;&#125;".format(response.content)) self.check_response_status(response) print("response: &#123;&#125;".format(json.dumps(response.json()))) return response.json()["data"] else: russell_logger.info('HTTP Stream Request/Response...') return response 不用flask的stream_with_context，则123456789101112131415161718# @auth.login_required# @flask_app.route('/api/v1/logs', methods=['GET'], endpoint='logs')# def get_logs_of_task():# ctx = _request_ctx_stack.top.copy()# new_request = ctx.request# new_g = ctx.g# parser = reqparse.RequestParser()# parser.add_argument('method', type=str, location='args')# parser.add_argument('id', type=str, location='args')# args = parser.parse_args()# if args.get('method') and args.get('method').lower() == 'kafka':# log_server = flask_app.config['KAFKA_BROKER_URI']# task_id = args.get('id')# if not task_id:# return jsonify(ED.error_response_norm(ED.err_req_data))# if not getattr(getattr(new_g, 'user', None),'id', None) == getattr(get_experiment_by_id(task_id), 'owner_id', 0):# return jsonify(ED.error_response_norm(ED.err_user_permission)) '''''']]></content>
      <categories>
        <category>快速入门快速实践</category>
        <category>一天</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>flask</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RussellCloud实习面经与入职经历]]></title>
    <url>%2FRussellCloud%E5%AE%9E%E4%B9%A0%E9%9D%A2%E7%BB%8F%E4%B8%8E%E5%85%A5%E8%81%8C%E7%BB%8F%E5%8E%86.html</url>
    <content type="text"></content>
      <categories>
        <category>Tips</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>面经</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让神哭泣-评《The Interview》]]></title>
    <url>%2F%E8%AE%A9%E7%A5%9E%E5%93%AD%E6%B3%A3-%E8%AF%84%E3%80%8AThe%20Interview%E3%80%8B.html</url>
    <content type="text"><![CDATA[PHP是世界上最好的语言电影资源下载百度网盘]]></content>
      <categories>
        <category>交流园地</category>
      </categories>
      <tags>
        <tag>影评</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非死不可]]></title>
    <url>%2FQ10.html</url>
    <content type="text"><![CDATA[非死不可 一 那天任何从工厂的流水线上下来，工作服一脱就去了工厂外面的一家网吧。收银台网管年轻稚嫩的脸，盯着任何掏出的身份证上那张同样年轻稚嫩的脸，看了许久许久，嘴里叼的香烟都要燃到牙齿上了。 “有这么好看？快点，我队友还等着我呢。”任何的眼睛说不上大，可是凌厉。说话一急促的时候，淘气的几缕发丝就飘进了唇红齿白间。 网管愣过神来，把身份证递还给了任何。 任何接过身份证立马揣进兜里，四下探望，人声鼎沸，烟雾缭绕。任何随便找了一台电脑开始上网，和素未谋面的游戏情侣一起厮杀。任何一直眉头紧锁，第三把还没开始就关了游戏。然后她漫无目的地浏览起了门户网站。 也不知道看了多少明星八卦再加多少搞笑段子，任何握鼠标的右手，再也没有那么勤奋地点点点滑滑滑了；任何那两弯好看的眉毛下面毛细血管突出的眼睛，眼白挤开了瞳孔。 坐在她旁边的同样是一群稚气未脱的少年，他们头发染成各式奇特的颜色，敲键盘的手上一定有一枚不知是钻石还是玻璃还是塑料的戒指，以及一支刚好燃掉一半的香烟。 任何斜眼看过去，他们手指下键盘的缝隙里，刚刚跌落的圆柱形的烟灰一瞬间就损失了形状，再也撑不起一根香烟的直挺，流露出其内心的空虚。 二 任何恢复意识的时候，一睁眼看到的不再是厂房宿舍上铺的床板，而是白得一清二楚的天花板。 穿着白大褂的人走过来，而不是穿着蓝色工作服的主管。白大褂把任何的眼皮拨弄来拨弄去，用笔记下了什么就转身离开。 任何知道自己在医院。可是想不起来自己为什么会在医院。所能回忆起的最近的场景，就是那根香烟，那根香烟，对，网管嘴里的那根，和坐在旁边上网的少年手指夹住的那根。 应该是那根香烟点燃了整个网吧，嗯，低头就能看到满地凌乱的布线，抬头就能看见墙沿裸露的电线，不发生火灾就奇怪了。任何不由得要咧开嘴笑，大概就是在一年前，坐在她前面的那个男同学，给她讲火线零线和变压器，讲得眉飞色舞，任何一句也没听进去。她只是傻傻地看着他讲，不时跟着他的手势看看纸上排列整齐的线路。那种整齐感，是任何在一片废墟般的家里无法奢望的。 后来看到图片上整齐划一的工厂流水线，任何跟回家探亲的表姐说，“嗯，带我去这里吧。” 任何忽然感到嘴角强烈的撕裂感。疼，但不钻心，因为一口气就呼出去了那些不可述说的疼痛。 三 后来的情节发展出乎任何的意料，也出乎任何的理解。 任何醒来第二天，就有两个警察跑来问话，问些稀奇古怪的话，任何只能一问三不知。 警察无可奈何，结束了毫无“营养”的问话，义正言辞道：“在这件事上希望你不要有任何隐瞒，坦白从宽抗拒从严。” 任何陡地怒了，“你以为我在隐瞒什么！？” 两个穿制服的面不改色耳语一番，稍年轻的那个咳嗽了两声，带着明显的装腔说道： “十九条人命可不是什么小事，所有知情不报都是隐瞒，会酿成特别严重的后果，请你务必——嗯哼——知无不言，言无不尽。” 任何差点没晕过去。敢情警察怀疑她背负了十九条人命？ 很想解释的时候，发现自己只能只会说一句我不知道，任何知道，任何不知道。 任何第一时间想起来自己在宿舍床边的桌子上写了半封信，那是在她发现男朋友劈腿后又在存款个位数的情况下被扣一个月补贴的当头，胡乱发了一通牢骚。不消说，任何在信中提到想杀人。 任何的信，没有写收信人，但是任何心中有一个默认的收信人。当然不是她那负心的男朋友，而是那个给她讲火线零线和变压器的男同学。 大概任何永远也不会理解，是那个男同学，给她完成了这个堪称“伟大”的心愿： 这个月真惨，糟透了，没一件好事情。过几天就十九岁生日了，我就这么活 了十九年，还没交够十九个男朋友。当我死的那一天，总该有十九个十九岁的男 孩子陪我才好。贾史久三个字一共十八笔，他也就刚好活了十八笔。我能活到今 天，不晓得是运气还是霉气呢。 四 贾史久他爸叫贾历长，不过贾历长的生命历史着实不长，十九岁不到就一命呜呼。贾历长倒不是因体弱多病罹患绝症而死，而是死在了坦克底下。贾史久知道他爸小时候老喜欢坦克了，所以觉得他爸能在最青春的年纪死于所爱，实乃是一种伟大。何况，贾史久他老妈当年十几岁挺个大肚子做了未嫁的寡妇，更是显出了贾历长的英雄气概。 虽说贾史久从小没见过亲爸爸，但是后爸陆陆续续好几个，待他也好，逆来顺受，好吃好喝好玩招待。贾史久也给他妈争气，从小就是各种第一专业户。 贾史久十三岁那年，有好事的邻居问他是不是他妈和中科院某科学家生的野种，要不咋这么聪明呢。贾史久没吭声。 当晚半夜贾史久爬到邻居家，对供电线路做了点手脚，然后一身轻松爬回家一觉睡到天亮。第二天晌午的时候传来噩耗，邻居一家三口死于触电。 这出乎贾史久的预料。本来只想教训一下那个满口跑野种的女家长的，不料买一送二。贾史久后来听说，女家长在厨房触电后男主人和小孩都跑过去扶人，所以全家跑阴曹地府一起吃午饭了。 是他们愚蠢。贾史久这样想着，心中负罪感也就慢慢释然了。 不过贾史久心中还是有些疙瘩，想要搬家，正好母亲改嫁，也就离开了这个时刻提醒着他血债的地方。搬家伴随着转学，也就是这年秋天，他作为插班生，认识了任何。 五]]></content>
      <categories>
        <category>交流园地</category>
      </categories>
      <tags>
        <tag>小说</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批判性思维结课录]]></title>
    <url>%2F%E6%89%B9%E5%88%A4%E6%80%A7%E6%80%9D%E7%BB%B4%E7%BB%93%E8%AF%BE%E5%BD%95.html</url>
    <content type="text"><![CDATA[董毓老师暂时离开，批判性思维不会离开14级种子班的批判性思维是6月26日（星期一）开的课，由于白天全天上课的缘故，不到两三天的光阴，我们和任课的董毓老师便有相交甚久之感。 第一天董毓老师令我们自主阅读，完成习题。要求的阅读内容不算少，小半本教材。很久没有咬文嚼字过的我们，时间一长还有些不适应。幸而带着问题读书，参与小组讨论，这才觉得不那么枯燥。而在讨论的过程中，总会有一些思维的火花闪现出来，这也是贯穿课程始终的一种学习方式。 董毓老师讲课的时候很有风范，镇定自若，“察言观色”的意识和能力很强，和我们互动很多，这让我们很难开小差。期间董老师请来华科的几位老师合作授课，课外一次在食堂吃饭与董老师同桌，董老师详详细细地问了我对这几位老师授课的一些看法。 董老师写的教材很“学究”，起初让我有一种敬畏之心，而授课时董老师广征博引，虽名为哲学教授，却展现了极强的自然科学素养；虽常年身在国外，却尤为关注国内热点事件，并且以批判性思维的眼光来审视之。这让我们兴致很高，启发很大。 这门课程注重思维训练，我们虽然不能背诵其中一些内容，但是在批判性思维的意识和能力上都有了较为明显的提升。首先是意识方面，连续一周多耳濡目染的听课与讨论，可以说形成了了初级的神经反射。而在能力方面，对图尔明模型等一些思维工具的学习与应用，也让我们在批判性思维的全面性和有效性等方面有所突破。 以罗伯特·恩尼斯对批判性思维的定义，“批判性思维是理性的、反思性的思维，其目的在于决定我们的信念和行动。”，我们对批判性思维的认识是渐进的、发展的。结课当天我们每个小组都做了GRE论文、正反证和实例分析这三个答辩展示，同学们在答辩中对应用批判性思维的过程的表述也让我看得更多更远，我从中认识到集思广益也是批判性思维“反思性”的一个重要体现。 董毓老师最后对我们班的评价挺不错，有不足，董老师也言传身教地反思自身授课是否详略得当快慢相宜。“师者，传道受业解惑也”。董毓老师虽然来去且匆匆，但批判性思维必将伴我们悠然见南山。]]></content>
      <categories>
        <category>交流园地</category>
      </categories>
      <tags>
        <tag>交流园地</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用Win10开机推荐的背景图作为桌面背景]]></title>
    <url>%2F%E4%BD%BF%E7%94%A8Win10%E5%BC%80%E6%9C%BA%E6%8E%A8%E8%8D%90%E7%9A%84%E8%83%8C%E6%99%AF%E5%9B%BE%E4%BD%9C%E4%B8%BA%E6%A1%8C%E9%9D%A2%E8%83%8C%E6%99%AF.html</url>
    <content type="text"><![CDATA[找到他们！这些图片的位置在：C:\Users\YOUR_USER_NAME\AppData\Local\Packages\Microsoft.Windows.ContentDeliveryManager_cw5n1h2txyewy\LocalState\Assets。 2017-07-15 22:45:27 更新：支持Chrome插件Momentum的背景图。 让代码来解决问题！代码中文档已经写好了如何使用~~~~ 不过还是列个关键字！ Win10 Python2/3 pip install pillow filterWinStartBg.py:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#!/usr/bin/env python# -*- coding: utf-8 -*-import sysreload(sys)sys.setdefaultencoding('utf-8')__author__ = 'Danceiny'__doc__ = """本模块实现以下功能：2017-07-15 22:45:27 更新：支持Chrome插件Momentum的背景图。1. 将Win10开机时的背景图片(DIR)复制到指定目录(PIC_DIR)，并根据文件类型重命名。2. 删除指定目录下不适合作为桌面背景（不满足DEFAULT_RESOLUTION）的图片。使用方法：在以下代码中的【自定义背景】区自定义你的变量，然后直接运行本文件： python filterWinStartBg.py, 再到【Windows设置】-【个性化】-【背景】-【背景】选择【幻灯片放映】，【为幻灯片选择相册】设置为PIC_DIR.！！！！即可将Win10开机时的好看的背景图设置为桌面幻灯片背景啦！！！！！！！！！！适用环境！！！！1. Win102. Python2/33. pip install pillowCopyrights @ Danceiny 2017-07-09 MorningDanceiny@GitHub &amp;&amp; danceiny@gmail.com还可参考：[python 设置windows桌面背景（从网络抓取）](http://www.cnblogs.com/qianlifeng/archive/2012/05/10/2494005.html)"""import osimport shutil # for copy/move fileimport imghdr # determine img type###################### 自定义常量 ####################USERNAME = 'huangzhen'MOMENTUM_VER = '0.95.3_0' # chrome 插件 momontum的版本号,可根据下面代码中的MOMENTUM_DIR进入文件管理器中查找PIC_DIR = r''DEFAULT_RESOLUTION = (1920,1080)###################### 自定义常量 ####################DIR = r'C:/Users/&#123;&#125;/AppData/Local/Packages/Microsoft.Windows.ContentDeliveryManager_cw5n1h2txyewy/LocalState/Assets'.format(USERNAME)MOMENTUM_DIR = r'C:/Users\&#123;USER&#125;\AppData\Local\Google\Chrome\User Data\Default\Extensions\laookkfknpbbblfpciffpaejjkokdgca\&#123;VERSION&#125;\backgrounds'.format(USER=USERNAME,VERSION=MOMENTUM_VER)PIC_DIR = r'C:/Users/&#123;&#125;/Documents/Beautiful/Background'.format(USERNAME) if PIC_DIR == '' else PIC_DIRDIR = DIR.replace('/','\\')PIC_DIR = PIC_DIR.replace('/','\\')def rename(path): for filename in os.listdir(path): all_filename = os.path.join(path,filename) if os.path.isfile(all_filename): if filename.find('.') &lt; 0: img_type = imghdr.what(all_filename) suffix = 'jpg' if img_type == 'png': suffix = 'png' elif img_type == 'gif': suffix = 'gif' elif img_type == None: os.remove(all_filename) continue newname = '.'.join((all_filename,suffix)) os.rename(all_filename,newname)def copyfiles(oldpath, newpath): if not os.path.exists(newpath): print('你指定的目录不存在，我要创建它^_^') os.makedirs(newpath) for filename in os.listdir(oldpath): all_old = os.path.join(oldpath, filename) if os.path.isfile(all_old): is_exist_flag = False for newfilename in os.listdir(newpath): if newfilename.split('.')[0] == filename: is_exist_flag = True print(' '.join(('目标目录已经存在该文件',filename,'我不会复制它的。'))) break if is_exist_flag == False: shutil.copyfile(all_old, os.path.join(newpath, filename))from PIL import Imagedef get_img_resolution(filename): # img = Image.open(filename) # imgSize = img.size #图片的长和宽 # maxSize = max(imgSize) #图片的长边 # minSize = min(imgSize) #图片的短边 # return imgSize return Image.open(filename).sizedef del_unfit_imgs(path,mode='strict'): #'strict'模式下删除该路径下所有尺寸不是DEFAULT_RESOLUTION的图片，非stric模式下删除长宽均小于默认尺寸的图片（momentum有很多不满足我原来设想的标准尺寸要求的美图啊~~~） for filename in os.listdir(path): all_filename = os.path.join(path,filename) if os.path.isfile(all_filename): if imghdr.what(all_filename) == None: os.remove(all_filename) continue imgSize = get_img_resolution(all_filename) if mode == 'strict': if max(imgSize) != max(DEFAULT_RESOLUTION) and min(imgSize) != min(DEFAULT_RESOLUTION): os.remove(all_filename) else: if max(imgSize) &lt; max(DEFAULT_RESOLUTION) and min(imgSize) &lt; min(DEFAULT_RESOLUTION): os.remove(all_filename)if __name__ == '__main__': copyfiles(DIR, PIC_DIR) copyfiles(MOMENTUM_DIR,PIC_DIR) rename(PIC_DIR) del_unfit_imgs(PIC_DIR,mode='non_strict') 给Gist来个Star吧]]></content>
      <categories>
        <category>Tips</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>桌面</tag>
        <tag>Win10</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebServer的日志系统实现分析]]></title>
    <url>%2FWebServer%E7%9A%84%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90.html</url>
    <content type="text"><![CDATA[123456789101112131415@Singletonclass LogCenter(object): def __init__(self): self.logger_map = &#123;&#125; def get_logger(self, name): """ return logger""" if not self.logger_map.has_key(name): self.logger_map[name] = MyLogger(name) return self.logger_map[name]# Usage:# data_logger = LogCenter.instance().get_logger('DataControlerLog')# except Exception,e:# data_logger.error("Data Controler delete data error, msg=[%s]" % ,repr(e)))# result['code'] = ED.err_sys]]></content>
  </entry>
  <entry>
    <title><![CDATA[中国电影人最缺乏的是耐心吗？]]></title>
    <url>%2F%E5%9F%BA%E4%BA%8E%E6%89%B9%E5%88%A4%E6%80%A7%E6%80%9D%E7%BB%B4%E7%9A%84%E6%96%B0%E9%97%BB%E8%AF%84%E8%AE%BA%E5%AE%9E%E4%BE%8B%E5%88%86%E6%9E%90.html</url>
    <content type="text"><![CDATA[中国电影人最缺乏的是耐心吗？标签（空格分隔）： 论证 分析 批判性思维 电影 中国电影 冯小刚 导演 小鲜肉 介绍本文对以下原文进行基于批判性思维的实例分析。 last updated: 2017-07-04 20:04:51 原文标题：老炮冯小刚又在捏观众这个软柿子了作者：张丰 [上影股份总公司总经理、上海联和电影院线有限责任公司董事长]来源：公号“冰川思享库”（ID:ibingchuansxk） 随着电影市场的扩展和房地产一样陷入瓶颈，最终会出现真正有技术含量的竞争，到那个时候，“工匠精神”才会值钱。 冯小刚为了宣传新电影《芳华》真是拼了，不但上央视《朗读者》节目去读了一首诗，还在上海电影节上炒作了一把。他大骂观众，认为中国“垃圾电影”横行的责任在“垃圾观众”太多，“你不去捧场，就没（垃圾电影）这东西，往往垃圾票房还很好。” 这话出自冯小刚之口，着实让人吃惊。要知道，在国内导演中，冯小刚被认为是最懂市场的。从90年代开始，几乎每一部他拍的电影，都很叫座。 可以说，冯小刚三个字已经成为票房的保证，中国电影观众，不管垃圾不垃圾，可都是看着冯小刚的电影长大的。 没有谁一出生就拥有绝佳的电影品位，所谓观众，其实是由电影创造的，有什么样的电影，就会有什么样的观众。 因此，我们甚至可以说，是以冯小刚为代表的导演，塑造出了中国的电影观众。如果说中国电影观众很“垃圾”，首先应该检讨的就是冯小刚本人，其次才是张艺谋和陈凯歌。 冯小刚的愤懑，很有可能和去年的电影《我不是潘金莲》有关，这部在上映前被寄予厚望的“艺术片”，拥有范冰冰这样的超级明星，但最终票房仍然惨败。 这说明，最近几年，中国电影观众确实发生了某种变化，冯小刚第一次把不住市场（观众）的脉了。 围绕《我不是潘金莲》的争议有很多，其中最轰动的就是冯小刚与王思聪的互撕。冯小刚认为，万达院线为这部“艺术片”的排片场次太少，而王思聪和万达则坚持“还是市场说了算”，最终，冯小刚和投资方华谊兄弟，并没有说服万达。 对冯小刚来说，这是一次标志性事件。在此之前，冯小刚可以说是不折不扣的“市场派”，他也并不反感请超级明星，不管是舒淇还是范冰冰，都是大牌。 而在《我不是潘金莲》之后，冯小刚似乎赌气似的变成了“艺术派”，开始抱怨观众不识货，抱怨明星的派头大。 毫无疑问，冯小刚陷入了某种创作危机。他不缺乏商业片的经验，但是他的老北京幽默，对90后、95后们不再有吸引力，他的铁杆粉丝是70后和80后，这让他有一种被抛弃感。 明年就60岁的冯小刚，已经是中国电影的“老人”了吗？至少他是不甘心的，他还要证明自己，从《我不是潘金莲》开始，他几乎在每个场合都标榜电影的艺术性，到今天痛骂电影观众，可谓是逻辑上的某种必然。 中国电影确实存在很大问题，但是，中国电影最健康的部分，就是观众了。 今年，一部小成本印度电影《摔跤吧，爸爸》在中国取得了票房与口碑的双丰收，这样一部小成本制作的电影，却俘获了大量观众，这也让中国电影人开始反思，中国电影到底是哪里病了。 冯小刚所说的排场很大、后面跟着五六个跟班的著名演员，很有可靠是被很多老艺人攻击的“小鲜肉”，零演技，但是光靠颜值就能赚大钱的青年演员，确实是中国电影浮躁的一个集中体现。但是，这些“小鲜肉”并不是中国电影堕落的原因，而是结果。 中国电影进入了资本驱动时代。院线的扩张，几乎与房地产的蓬勃发展同步，愿意投资电影的巨头也在增多，连阿里、腾讯都在进入电影市场。可以说，中国电影正处在非常好的时代，或许正是市场快速膨胀，才让“好片难寻”的感受更为强烈。 这也就能解释冯小刚讨厌的小鲜肉名演员，为什么能挣那么多钱。电影市场和小鲜肉一样年轻，而他们也正在殚精竭虑地要赢得未来，国产电影审美的的低龄化、低智化，也就可以理解。涌向影院的观众太多了，而没有足够多元化的影片能对观众做出区分。 戴锦华教授在和冯小刚对谈时，谈到了院线的垄断，这确实是一个重要的原因。院线的“票房预期”判断，导致一些艺术片根本进不了排片，最后自然也就不愿意有人再投资这样的片子。 成熟的电影市场，除了所谓商业片外，也会有艺术片、纪录片等各种所谓“小众片”的立足之地，这样才会有一个多元的“市场”，才会有编剧肯花时间推敲剧本，最终才能塑造和吸引一个更多元的观众群。 本届上海电影节祭出了“用工匠精神，打造中国电影”的大旗，算是找对了方向。所谓“工匠精神”，用著名思想家理查德·桑内特的话，就是那种“为了把事做好而把事做好”的精神，缺乏工匠精神的，可能不止是导演和编剧，还包括院线以及投资方。 在大家都能轻松赚到钱的时候，就谈不上真正的专业性，但是，随着电影市场的扩展和房地产一样陷入瓶颈，最终会出现真正有技术含量的竞争，到那个时候，“工匠精神”才会值钱。 桑内特认为，一个人发展出工匠级别的技艺，需要1万小时的练习，如果每天用上3小时，这也需要10年的沉淀，考验中国电影人的，不是决心，而是耐心。从冯小刚身上，我们已经看出中国电影人最缺乏的就是耐心，这可真不是什么好苗头。 分析论证理解主题论点核心论点：中国电影人最缺乏的是耐心。隐含论点：中国电影存在问题，问题症结在于中国电影人。 澄清观念意义 电影人包括电影制作人（导演等剧组人员）、编剧、演员等。不包括电影投资方、政府（广电总局？）、观众等。 耐心：电影制作人、编剧、演员等直接参与电影创作的人士在电影创作过程中遵循职业道德，不急于求成。 分析论证结构 &amp;&amp; 审查理由质量 &amp;&amp; 挖掘隐含假设 &amp;&amp; 考察替代论证 冯小刚的言论所呈现的论证 得出“冯小刚”缺乏耐心的论证 得出“中国电影正处于非常好的时代”的论证 得出“中国电影的观众很‘健康’”的论证 得出“中国电影有病的部分是电影人”的论证 得出“中国电影人最缺乏的是耐心”的论证 评价推理关系综合组织论证 参考 老炮冯小刚又在捏观众这个软柿子了 每日电讯：真正的好电影从来不缺观众]]></content>
  </entry>
  <entry>
    <title><![CDATA[WebQQ与聊天机器人的技术细节]]></title>
    <url>%2FWebQQ%E4%B8%8E%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9A%84%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82.html</url>
    <content type="text"><![CDATA[登录模块class Login(HttpClient) 类初始化1234567891011121314151617181920212223242526272829303132333435def __init__(self, vpath,qq_number=0,params=None): self.initTime = time.time() self.VPath = vpath # QRCode保存路径 self.UI_PTLOGIN2_URL = params.get('UI_PTLOGIN2_URL', '') self.QQ_LOGIN_URL = params.get('QQ_LOGIN_URL') self.ClientID = params.get('ClinetID') self.PSessionID = params.get('PSessionID') self.QQ_GROUP_API_URL = params.get('QQ_GROUP_API_URL') self.REFERER = params.get('REFERER') self.MaxTryTime = params.get('MaxTryTime',5) AdminQQ = int(qq_number) # 1. 从 'http://w.qq.com/' get # 2. 从 UI_PTLOGIN2_URL = 'https://ui.ptlogin2.qq.com/cgi-bin/login?daid=164&amp;target=self&amp;style=16&amp;mibao_css=m_webqq&amp;appid=501004106&amp;enable_qlogin=0&amp;no_verifyimg=1&amp;s_url=http%3A%2F%2Fw.own_qq_number.com%2Fproxy.html&amp;f_url=loginerroralert&amp;strong_login=1&amp;login_state=10&amp;t=20131024001' 获取登录页面（以w.qq.com为Referer头部）， 从login_html中获取APPID,SIGN（登录证书),JS_VERSION,MiBaoCss(?) # 3. 从login_html中获取mibao_css # 4. 开始时间 datetime.datetime.utcnow() ==》 millis # 5. 尝试MaxTryTime次：下载登录验证二维码，获取cookie，从QQ_LOGIN_URL = 'https://ssl.ptlogin2.qq.com/ptqrlogin?ptqrtoken=&#123;0&#125;&amp;webqq_type=10&amp;remember_uin=1&amp;login2qq=1&amp;aid=&#123;1&#125;&amp;u1=http%3A%2F%2Fw.qq.com%2Fproxy.html%3Flogin2qq%3D1%26webqq_type%3D10&amp;ptredirect=0&amp;ptlang=2052&amp;daid=164&amp;from_ui=1&amp;pttype=1&amp;dumy=&amp;fp=loginerroralert&amp;action=0-0-&#123;2&#125;&amp;mibao_css=&#123;3&#125;&amp;t=1&amp;g=1&amp;js_type=0&amp;js_ver=&#123;4&#125;&amp;login_sig=&#123;5&#125;&amp;pt_randsalt=2' 登录，得到get的response，检查是否扫码（登录） # `login_html = self.Get((self.QQ_LOGIN_URL).format(util.getQRtoken(QRSig), APPID, util.date_to_millis(datetime.datetime.utcnow()) - StarTime, MiBaoCss, JS_VERSION, SIGN),Refer=self.UI_PTLOGIN2_URL)` # 6. 扫码后删除二维码图片 # 7. 记录登录账号的昵称 # 8. 从cookie中得到PTWebQQ # 9. 先后post,get两个url，验证是否登录成功。 # 10. 从response中获取VFWebQQ，MyUIN，并更新self.PSessionID # 11. 随机生成msgId，]]></content>
      <categories>
        <category>好玩</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>QQ</tag>
        <tag>聊天</tag>
        <tag>机器人</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebQQ与聊天机器人的玩法]]></title>
    <url>%2FWebQQ%E4%B8%8E%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9A%84%E7%8E%A9%E6%B3%95.html</url>
    <content type="text"><![CDATA[QQ小黄鸡VPS挂机版 该项目修改自SmartQQBOT这一项目，支持在VPS下nohup命令挂机。QQ协议说明请参考原项目。 请帮忙分析Android QQ协议：此项目现已稳定，在更新协议前不会有大更新。希望有人能跟我一起搞手机QQ协议，SmartQQ协议稳定性不是很理想。 重要：群聊被TX认为是极度危险的行为，因此如果账号被怀疑被盗号（异地登陆），群聊消息会发不出去。表现为程序能收到群聊消息，群聊消息发送返回值为发送成功，但其他群成员无法看到您发出的消息。大约登陆10分钟后您会收到QQ提醒提示账号被盗，要求改密码，同时账号被临时冻结。不知为何该程序刚运行时总是被怀疑异地登陆，当您重复解冻3次后（就是改密码），TX基本就不再怀疑您了，一般一次能稳定挂机2-3天。强烈推荐您用小号挂QQ小黄鸡！ This project is a chatting robot in QQ, implemented in Python. The robot uses Artificial Intelligent API to generate response. QQ is a popular instant chatting service in China, which is similar to Facebook Messenger. The robot supports group chatting and private chatting and should be only used for fun. Here is a similar project used to keep QQ account online with the function to record messages and forward to your E-mail. 登陆时采用QQ安全中心的二维码做为登陆条件, 不需要在程序里输入QQ号码及QQ密码。QQ自动回复私聊（无群聊功能）及留言邮件提醒版本请看这里。 如何使用从http://www.tuling123.com/openapi/ 申请一个API KEY(免费，5000次/天)， 贴到QQBot.py的第36行 (测试KEY：c7c5abbc9ec9cad3a63bde71d17e3c2c)修改groupfollow.txt,将需要小黄鸡回复的群的群名写入(小黄鸡必须为群成员),每行一个群名，请不要打多余的空格。（新版WEBQQ已移除获取群号的接口，输入中文群名请务必使用UTF-8编码）nohup python2 QQBot.py &gt;qbot.log&amp;ls若出现v.png则用QQ安全中心扫描，否则继续lscat log.log可以输出运行LOG强烈建议使用小号挂小黄鸡，已知QQ会临时封禁机器人的临时对话回复和群回复，原理未知，每次封禁约为10分钟。表现为发送消息返回值retcode 为 0 但其他人无法看到。长时间挂机会导致QQ被冻结错误，QQ安全中心提示发布不良信息据反馈此AI平台回复中带有少量广告。。。(如问iphone6价格回复小米799)功能 注：以下命令皆是在QQ中发送，群聊命令发送到所在群中 关于及帮助，在群聊中发送!about 群聊智能回复，在群中通过发送!ai 问题语句，则机器人向AI平台请求问题的回复并回复到群，带有!ai关键字时优先触发此功能 私聊智能回复，对于收到的私聊，机器人向AI平台请求该聊天记录的回复并回复给消息发送者 群聊学习功能，类似于小黄鸡，在群中通过发送!learn {ha}{哈哈}语句，则机器人检测到发言中包含“ha”时将自动回复“哈哈”。!delete {ha}{哈哈}可以删除该内容。学习内容会自动储存在database.群号.save文件。!deleteall可删除该群所有记录。注意learn和{之间有空格，{}与{}之间没有。 群聊复读功能，检测到群聊中连续两个回复内容相同，将自动复读该内容1次。 群聊关注功能，使用命令!follow {QQ昵称}!可以使机器人复读此人所有发言（除命令外）使用命令!unfollow {QQ昵称}!解除关注。例如 !follow 卖火柴的小女孩!。{QQ昵称}处可使用”me”来快速关注与解除关注自己，例：!follow me! 私聊直接聊天即可，不需要加任何前缀。 Refshttps://github.com/b3log/xiaov https://github.com/ScienJus/smartqq/wiki/%E7%99%BB%E5%BD%95-Api http://www.scienjus.com/webqq-analysis-2/]]></content>
      <categories>
        <category>好玩</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>QQ</tag>
        <tag>聊天</tag>
        <tag>机器人</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Hexo搭建个人博客站点全纪录]]></title>
    <url>%2F%E5%88%A9%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%AB%99%E7%82%B9%E5%85%A8%E7%BA%AA%E5%BD%95.html</url>
    <content type="text"><![CDATA[需求澄清 个人博客。 静态的即可。 可由GitHub Pages或者Coding.net Pages服务托管。 要有域名，好记。 博客中有图片，需要稳定的存储。 维护与操作系统平台无关（因为自己各种操作系统切换）。 技术选型Hexo + GitHub/Coding Pages双托管 + 腾讯云解析 + 七牛云图片存储 开始配置安装Hexo首先安装npm，使用npm安装hexo。 npm Hexo 主题Next安装：http://theme-next.iissnan.com/getting-started.html GitHub仓库地址：https://github.com/Danceiny/blogPages地址：https://danceiny.github.io/blog添加CNAME文件，指向blog.cannot.cc，Pages地址重定向到该域名。 Coding同上。 腾讯云解析已有域名（已备案）: cannot.cc 添加二级域名: blog.cannot.cc 添加CNAME类型的记录，记录值设置为danceiny.github.io. 把www.blog.cannot.cc记录到pages.coding.me. 顺便把cannot.cc解析到 http://danceiny.github.io 了。（原来在Github上的个人主页）。有空再修改。 注意： 腾讯云解析的记录值是比较需要关注的。 www是个神奇的东西，http://blog.cannot.cc 和 http://www.blog.cannot.cc 是不一样的两个东西。 七牛图床https://portal.qiniu.com/bucket/有很多官方工具可以使用，命令行，GUI，但是目前我感觉不太用户友好。访问秘钥就是两个：Access Key和Secret Key。Bucket像是GitHub里的仓库吧，我叫它对象存储仓库。 阅读次数统计 可在Next中配置，使用leancloud.cn 参见博客 社交分享直接在Next中开启jiathis即可。不支持https是个隐患。 站点搜索可选的几个服务都是收费的，所以我选了本地的搜索。按照Next的教程配置即可。 百度联盟http://union.baidu.com申请，未通过，网站内容还是少了点。 百度统计站点访问统计。百度统计的账号和百度联盟账号可以不一样，不过还是统一账号比较好，方便管理。 谷歌分析跟帖回复评论使用Facebook的评论系统。 网易云跟帖未引入，不过看起来效果不错。 SEO Hexo优化之为外部链接添加nofollow https://liuzhichao.com/2016/hexo-auto-nofollow.html https://eason-yang.com/2016/08/03/tips-for-hexo-and-hexo-next/ hexo高阶教程：教你怎么让你的hexo博客在搜索引擎中排第一 站点地图通过npm下载插件。有专门针对百度的。可做SEO。 sitemaps.xml RSS订阅通过npm下载插件。 Facebook Audience广告投放未搞定。 Hexo部署https://hexo.io/docs/deployment.html 可部署到百度，方便搜索引擎收录。 CNAME覆盖问题https://www.stayhungry.me/2015/07/26/%E6%90%AD%E5%BB%BAHexo%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/ 利用分支备份Hexo项目源代码在博客对应的GitHub项目上创建Hexo分支。Pages服务用的是master分支。 yaml重要配置文件不应该上传到公开项目。 去掉post的url中的日期permalink: :title.html 其他优秀的同类型博客http://litten.me/]]></content>
      <categories>
        <category>DOSOMETHING</category>
      </categories>
      <tags>
        <tag>个人网站</tag>
        <tag>博客</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言入门奇葩说-2]]></title>
    <url>%2FC%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%A5%87%E8%91%A9%E8%AF%B4-2.html</url>
    <content type="text"><![CDATA[表达式和运算符关于左值、右值和布尔值。 几个重要概念左值、右值、赋值、=和==能放到等号左边的通常在内存中都有一个能确定下来的位置；而放到等号右边的都必须有一个值。从这句话，就可以知道所谓=，即赋值，与传统数学符号系统里面的=，在含义上的差别是很大的。传统的等于号，对应于C语言的==。C语言的=，是把它右边的一个确定的值，赋给左边的一个“空箱子”（我说的空箱子就是人们通常说的内存位置）。这两个符号和概念不能混淆，因为考试经常考。 注释前面其实看的也挺多了，注释符号有两种，行注释//和块注释/*...*/。这个其实很好懂，在某一行里，//后面的，都是注释；在某一个文件里，/*和*/中间的，都是注释。那么注释是什么呢？笨蛋啊，读书笔记啊懂么。前面提到过编译器，编译器看到注释符号，自动就把注释给踢掉了，人家不翻译注释。这个就好像你有一本书写满了批注，找个翻译官来翻译，翻译官当然是翻译正文，哪管你写得歪歪扭扭的批注呢。所以无论你在注释里写什么，都不会报错。 By the way，注释的作用，和读书笔记一样。——怕以后看不懂。。。。。 数组、矩阵由于本人在学习C语言之前学过《线性代数》这门课，所以对这两个概念的理解和转换毫无压力。事实上我认为对这两个概念的理解对C语言是非常非常有帮助的。事实上数组这块是C语言的重点，有用，必考，考得特多。经常说几维数组，有点玄乎，但是略微知道矩阵的，就知道这两个是多么相似，而且方便理解了。所以，本人建议学习一下《线性代数》的第一章。里面很多知识，可以很自然地移植到C语言里关于数组的运算上来。 内存地址、指针这个属于比较高级的内容，但是二级C考试也考，考得还不少，不过一般都是选择题居多。先说内存地址，这个概念我认为是C语言（以及一系列C系语言，以及我没有接触过的其他语言）的核心。计算机毕竟是电子设备，软件不是虚无的，而且搭建在一定的硬件条件上的，这个内存地址，就是比较硬的——大地都是硬的~ 对于初学者，一脸懵逼是必然的，但是可以想象有一块莽莽苍苍的大草地，然而你却想在上面种一棵树！！！ 你买来了小树苗，这个小树苗就是你的右值。 你有一个小园丁，这个小园丁就是你的左值。 你对小园丁说，在北纬32°东经127°海拔1024m处，有一块空草地，因为我特么想在上面种一棵树，我又不能到那里去，所以我把这块土地给你——这就是int xiaoyuanding;//声明变量，由于没有初始化，此时这个变量是没有确定的内存地址的——这时候小园丁还没有去到那块土地上~，然后，嗯，树苗给你，把它种上去——xiaoyuanding=XIAO_SHU_MIAO;//变量初始化，小园丁接到你的指令，就去那块土地了，所以这时候就有确定的内存地址了——北纬32°东经127°海拔1024m处。 整个过程也可以快点完成，不拖沓——int xiaoyuanding=XIAO_SHU_MIAO; 命名规范什么需要命名？变量(包括一般的数值变量、数组、指针）和函数——这个是我自己临时想到的，可能不完善（但是需要一个名字来称呼不是很理所当然么）。 关于命名，有一些是死规定，不能触犯的。比如关键词不能拿来命名，不能以数字开头，不能用-（因为看起来就是减号），不能……所有这些，请查阅权威性文档——教材和网络。还有一些是习惯。比如有驼峰式命名法， getMax 这个名字就是驼峰式命名，与之对应的就是get_max。另外，像常量通常全部用大写，比如INT_MAX。 不过最重要的一点，还是要借鉴中国古代人取名，取字，取号，取谥号，要有意义，要能概括这个人（谥号就是用来概括一些名人大贤的）。所以你看到上面这些我取的名字，是不是一看就知道它们代表什么含义咯。这个没有具体的要求，所以可以形成自己的风格（代码风格的一个重要组成部分，另一部分是括号的位置和空格缩进）。 矩阵元素最大值1234567891011121314151617181920212223242526272829#include&lt;stdio.h&gt;int main( )&#123; int i, j, c, max ; /* static是一个修饰符，静态的意思，至于这个静态在C语言里面有什么含义，可以百度。 尤为重要的，static的一个是作为计数次数的变量修饰符，这是一种比较经典的C语言考题题型。 进阶的，在我的这篇文章里，也有提到一点&lt;http://huangzhen.farbox.com/post/cyu-yan-dian-di/chapter7-han-shu-mo-kuai-hong-ding-yi&gt; 摘录几点（可能有点抽象）： 静态存储区和栈不同，不会随着函数的退出而消失。事实上，静态存储区的变量会和整个程序的寿命一样长。 static的第二个特性，是信息隐藏，static变量只在定义它的范围内可见，在其他范围内不可见。这也是static变量与全局变量的区别，虽然他们被保存在同一块内存区域。 如果static用来修饰函数，这个函数只在当前的.c文件中可见，这样就可以在不同的.c文件中定义同名函数而不冲突。 */ static int a[3][4]=&#123;&#123;6,-5,11,3&#125;,&#123;8,9,4,7&#125;,&#123;2,13,1,-10&#125;&#125;;//这是一个二维数组，通过大括号&#123;&#125;聚合在一起 for (i=0; i&lt;=2; i++)&#123;//二维数组a可是看成是一个3x4矩阵，这里i从0到2，可以看作是循环遍历矩阵的每一行（3行4列） max=a[i][0]; //首先假定每行的第一列元素是最大值 c=0;//c是column的首字母，代表列数 for ( j=0; j&lt;=3; j++)&#123;//在每一行里，开始循环遍历列了，每一行都有4列。 if (a[i][ j]&gt;max) &#123;//假定的最大值比这个a[i][j]还小？！ max=a[i][ j]; //那么最大值就是这个a[i][j]了！ c=j;//记录这个新的最大值的列数 &#125; &#125; printf(&quot;max=%2d,row=%d,column=%d\n&quot;,max,i+1,c+1);//这一行的最大值找到了，它的行号和列号我们也知道 &#125; return 0;&#125;]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>C语言</tag>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言入门奇葩说-1]]></title>
    <url>%2FC%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%A5%87%E8%91%A9%E8%AF%B4-1.html</url>
    <content type="text"><![CDATA[什么是程序，什么是代码，什么是语言，什么是编程程序是一个很老的词，我们可以联想到流程、程式、表达式、顺序等词语。 代码也是一个很老的词，码是符号，代是说这种符号代表了某种意思。文字就是一种代码。 语言也是一个很老的词，说的写的，就是语言。 以上和编程联系起来，就从一个很老的世界，跳入了一个新的世界——从计算机编程的角度讲，这一切不过只有几十年的历史而已。比如C语言的创始人好像还没死欸。 我理解的编程就是，面对现实世界中的某些问题——尤其是单调乏味有限有规律的问题，人们为了提高效率、拒绝重复等原因，依托现代计算机等好用的硬件，又借用别人开发好的计算机操作系统，并利用与某门编程语言相适应的一整套开发工具，最后用键盘和鼠标等输入设备，写小说一样写代码，写完要检查对不对——自己可以检查，也可以搬出你所利用的开发工具中的某个东东帮忙检查，这个检查过程通常我们称作测试，测试完了就说明你写对了——当然没有语病是不够的，你的小说还应该要有一定的主题，要表达一定的情感，要有确定的目的，如果没有，那仍然是一篇失败的小说。所以最后，和最开始，编程就是为了解决那个问题而来。 现在给你出第一个问题，假如你是小学生高斯，你老师让你去做题，算1+2+3+…+100。可是你没有高斯那么聪明。旁边的小朋友1+2=3，3+3=6，6+4=10，…，中间不小心忘了、写错了，又重头再来，最后终于赶在日落之前算出来了，等于4050。可是你有一台计算机。这时候，你设想了一个这样的“算法”：所求的和最开始是0，第一次加1，第二次加2，第几次就加多少，总共加一百次就好了。那我有一百个仆人，他们每个人加一次，我只要问最后一个仆人，就知道结果是多少了。这时候你又穿越到高中的数学课堂，老师正在讲流程图。嚄，然后你敲下：12345678910#include&lt;stdio.h&gt;int main()&#123; int i; int sum=0; for(i=1;i&lt;=100;i++) sum += i; printf(&quot;哈哈哈，我一定比高斯算得还快！答案是%d&quot;,sum); return 0;&#125; 说实话，这个程序够我讲半天了。但是呢，根据马克思的矛盾论，我们要先抓住主要矛盾的主要方面。 第一行，（注意，写代码的时候我们经常说多少行，这和小学时候学语文差不多吧，中心思想在某篇课文第几行？）在学习C语言的第一个月里，第一行请照抄。根据英文翻译，可以推测这是包含个啥对不对。俗话说的好，没有旁征博引的文章怎么能称得上文章呢。 第二行，关键的地方了，关键在第二个单词，main，尼玛这是个大写的关键啊，但是呢，这个main不能大写。。。。。这个main啊，是整个程序的入口，是大门。你要去别人的家里，总得从大门进去吧。想起高中的程序框图没有，这个main就是那个开始！——所以，每个程序都有一个main。 第三行，怎么就一个大括号呢？等等再看。 第四行，int，好眼熟，i又是啥？要我说呢，int就是一个帽子，在第二行这顶帽子给main戴上了，现在又给i戴上了。这顶帽子啥意思暂时不用管。 第五行，和上面一行长得好像，sum应该是和吧，sum=0欸。 第六行，有个for，这个介词啥意思？又是int，括号里面i出现了三次！！！还1，100，++的。猜一猜，前面不是介绍过从1加到100的算法吗？ 第七行，+=是什么鬼符号？不懂。 第八行，print是打印的意思！！哈哈，英语水平真是高啊，后面加个f，应该是函数、功能function的意思吧。那么，就是说它有打印的功能咯？打印啥呢？这不是用一个括号给括起来了嘛。前面汉字好懂，中间%d不懂，最后又有一个sum，再看看整句话，那个%d是不是就是sum呢。 第九行，return是返回的意思！返回0？这是什么鬼。——这个鬼好神秘的~ 第十行，又是一个大括号。嚄！是右边的大括号！！还记得第三行的大括号吗，他们不是cp么。。。cp怎么能分开呢，他们可是生生世世在一起永远不分离的。——不过一般都是异地恋呢。 OKay，程序代码分析完毕。就十行，比旁边小伙伴从1加到100写99行算式总归是精简了好多呢。但是这特么没有告诉我们结果啊！现在，我再说几个重点： C语言是一门编译型语言，写好的代码，一般是存储在一个名为NAME,后缀为c的NAME.c文件中，但是这个文件需要经过编译，才能被计算机所认识。来做这个编译工作的——其实就是翻译，叫做编译器，compiler。 编译好之后，然后就可以生成了——好比小说写好后出版。 然后就可以运行了，run。 然后就可以看到程序的结果了——谨记，编写一个程序，肯定是希望它有输出的，汇报总该要有，总不能默不作声吧，那样谁知道它到底干了些啥。 以上是我归纳的简化版过程——真实的过程是比较复杂的。但是这个简化版够用了。 以上部门仍然是为了勾勒一个初步的印象，至于具体的学习，请看下一部分——入门。 入门我无意在这里重复所有C语言教材都会有的说教部分。下面我点几个需要仔细阅读教材中相关内容的东东： 关键词，这个不多，就是几十个英文单词罢了，过目一遍，以及什么是关键词； 数据类型，比如int，float，char； 运算符，比如+,-,*,/,%,;包括其他一些标点，比如,,;,{,[… 表达式，例如3+4,x+3; 控制结构，例如while,for,if。主要就是这两个循环和一个如果。 printf和scanf函数。打印，扫描。输出，输入。 别看只有6点，这几乎是你需要学习的六成内容了。现在的话，可以马上去翻一翻目录，找到有关以上6点的章节（目录没找到那也不要紧，还可以上网），认真仔细地阅读一遍，标出你认为的重点，尤其是一些表格和definition。然后再阅读一遍本文。然后详细地阅读刚刚看过的教材中的部分。 实践出真知请打开VC6.0，新建一个.c文件，把上面那个跟高斯比赛的程序代码拷贝到编辑框，保存，然后在VC6.0的面板上，找到一个感叹号！，点击这个按钮，程序就可以运行啦。注意两点，鼠标悬浮在感叹号上面的时候，注意看显示出来的解释；点击感叹号之后，注意看编辑框的下面那个框里面发生了什么。如果报错了，不好意思，我的程序有一点问题，请通知我。 高级一点点的下面的程序，可能乍看之下还有点难，放在这里只是让你有个对照。这个程序的功能是转置一个矩阵。如果学过线性代数的话，你可以很快理解这个过程。不理解也不要紧，因为这个程序里面出现的东西都是以后经常见到的，早点见面可以熟悉一下脸嘛。1234567891011121314int main( )&#123; static int a[2][3]=&#123;&#123;1,2,3&#125;,&#123;4,5,6&#125;&#125;; static int b[3][2], i, j; printf(&quot;array a:\n&quot;); for (i=0; i&lt;=1; i++) &#123; for ( j=0; j&lt;=2; j++) &#123; printf(&quot;%5d&quot;,a[i][ j]); b[ j][i]=a[i][ j]; &#125; printf(&quot;\n&quot;); &#125; printf(&quot;array b:\n&quot;); for (i=0; i&lt;=2; i++) &#123; for ( j=0; j&lt;=1; j++) printf(&quot;%5d&quot;,b[i][ j]); printf(&quot;\n&quot;); &#125;&#125; 顺便，有木有觉得上面这个程序很丑？那是因为，这不是我写的。]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>C语言</tag>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言入门奇葩说-0]]></title>
    <url>%2FC%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%A5%87%E8%91%A9%E8%AF%B4-0.html</url>
    <content type="text"><![CDATA[About！！！这个部分略过也没有大碍的。可以直接从关于读书开始看起。！！！ 有个小伙伴加电脑白痴说要考二级，问我要不要报培训班。我听了当然觉得很愚蠢。如果我没有考过C语言的二级，我或许不敢发表什么定性的评价。可是我是考过计算机等级考试二级C语言的男人啊。当然没必要报啥培训班了。我当时就想说，C语言啊，还不如我来教呢。我当然不是什么大神，离大神大概有银河系的思念的距离吧。 但是既然有这个想法，肯定是有我的考虑的。第一个，也是最重要的原因，最近在读一本C语言的书，赵岩的《C语言点滴》。这本书可以说很大程度上改变了我对C语言教材、参考书的刻板看法。因为这本书实在是太有趣了。具体介绍这里就不展开了。所以这本书也就激励我，用这本书的思维，去述说C语言，让一个完全没有概念的小白理解C语言。因为，白居易说得好啊。白居易说了啥我也不知道。我只知道白居易的诗有个很大很大的特点。 另外吧，从去年年底开始接触的一些东西，基本上都是用的C/C++。自然还要接触很多，更加需要温习、深入。而且老师当时就说了，你们应该把这些个项目的工作原理跟你们父母讲得明白，那才是真的明白了。 还有吧，感慨自己学C语言时间太短，未能及时领悟它的博大精深，又走了许多弯路。主要也是因为自己当初缺乏指导。 下面简单说下我当初的入门之旅吧。 也算是我写给自己的一个回顾吧。 计算机背景知识首先当然要介绍这个，可以说这个是必要的先修知识。毕竟C语言可是跑在计算机（包括许多你不认为是计算机的小小的计算机）上的。小学一年级的拼音学得很好。大概四年级的时候把小学阶段的字都差不多认全了。小学五年级开始上网。网吧。单机游戏。侠盗飞车，CS，暴力摩托。QQ加陌生人好友聊天。（这时候拼音学的好就派上用场了）这时候好像学校也开了电脑课，好像就是老师在上面讲些最基础的知识和PPT,WORD这样的基本操作，我印象最深刻的就是看到老师用五笔打字，按了四个键就出来一大串字，觉得好牛啊。后来自己操作的时候就去做PPT（其实就是创建一个PPT文件然后写个标题画个图，反正不懂随便点点）。六年级开始逛门户网站。那时候热爱军事，战斗机。大概就是小学毕业那会嚷嚷着想买个游戏机。家里人不肯。后来折衷买了个学习机。其实就是带键盘的游戏机。那时候我老姐差不多上大学了。她让我去练打字，学五笔。花了一个月把五笔学会了。当时我真的挺佩服自己的，因为五笔字根口诀并不会背，只是跟着打字软件学习，但是大部分字都能打得出来。以及后来我不会什么方法却学会了拧魔方差不多一个道理，我用的是模糊记忆法。（其实平常读书也都是这样浑浑噩噩）初中电脑课我就一直玩金山打字那个警察追小偷，不断刷新纪录。初二的时候老姐把不要的电脑给我了。我玩了一个暑假的游戏，各种小游戏、单机游戏玩了个遍差不多（因为家里从来没有网）。暑假快结束的时候发现一个超好玩的篮球游戏。然后我的整个初三就在玩这一个游戏。在学校住宿，晚上请假回来玩游戏。有时候还通宵（我的人生第一个通宵啊）。通宵怕老妈知道我在玩电脑，就把电脑放在被窝里面玩，好热啊，电脑温度太高，然后就崩了几回。我只记得一次是我拿去修的，重装系统。当时电脑店里面那个口吃问我装win7还是xp，我问有什么区别，他说win7是新出的系统，xp要稳定些，我说那xp吧。看他一点也不熟练地给我装系统，满屏幕全他妈是我看不懂的英文，我好佩服这个口吃（好像还有点瘸）。他要价30块。我借口说没带那么多，给了26，他也收了。然后顺理成章的成绩直线下降，对学习也越来越没有兴趣。那时候顺便还用酷狗播放器制作歌词，改编歌词放进去，然后拷贝到电子词典里面放歌看歌词，好不快活。高中继续玩那个游戏。不过一中离家太远了，我又不能把笔记本带学校去。去网吧也基本上去的是高中旁边的学校。初三之后就再也没有练过打字了，后面所有对电脑的接触就是上网，看新闻，打游戏。大一说不让带电脑。一开始也没敢带。国庆时候回去把电脑带来了，还是打那个游戏。打了这么多年都不会腻，我觉得这一定是真爱。高二暑假买了个智能手机，高三玩手机比较多，毕竟那时候老班对手机比较宽容。高二开始看美剧，第一部就是《越狱》，无法自拔。高三为了练听力，看《生活大爆炸》。忘了说一点，大学之前的网吧上网经历，我因为有一台不能联网的笔记本，和一个可以放音乐的电子词典，和一个手机，所以我每次都带了U盘，去下载视频啊音乐啊小说啊之类的东西。所以这个经历也成为了我的一个习惯。现在看来还是不错的经历。因为那时候就把很多下载网站摸得还算比较熟了。像国内大部分下载站，都有无数的广告诱惑你去下载，我那时候上了无数的当，自然就摸得很清楚了。但是由于英语水平有限，对国外的网站基本从未接触过。大一继续打游戏看美剧。大一上那段时间，一有时间在寝室里面呆着我就看美剧。快期末的时候电脑挂了。拿去检查说可能是主板坏了，要修的话划不来，毕竟是这么老旧的电脑了。幸好在期末之前一段时间挂了，我有时间复习，所以那次期末考也是目前为止大学考得最好的……大一寒假的时候，研究生班主任在班群里面说，下学期要学C语言了啊，然后发了一个PDF，让我们看看。我好奇地打开看了下，一脸大写的萌逼啊有木有。所以后来我特别能体会新手的痛苦。我大概看了那本书的第一章，看完之后完全不知道这是在说啥。所以就没看了。大一下开学后不久我买了电脑。对电脑完全不懂啊，我姐也不太懂。问同学买了啥，那给我来个同款吧。 学校开的C语言课开始上C语言课了。我住东边，上课在西边。我又是一脸大写的萌逼啊。老师鼓励带电脑上课，我特么不难背么。一台笔记本也有几公斤啊。第一次C语言上机课很快就开始了。我拿了还没翻过的教科书去上课。按照老师指示的，打开VC6.0,新建一个cpp文件，往编辑框里面写代码。——我当然不会写什么代码，我照着书的例子敲的。然后照指示保存，再按一个键（这个键的功能就是编译+运行，这个之后再说），妈蛋结果不通过，报了好多error。我当时就怒了，辛辛苦苦照着教科书打字那么久，结果却不能运行！！！当时隔壁坐了个编程大神。大一认识的时候他说他高中就参加过编程比赛拿过奖，一来就说准备转计算机学院的。我问他这个程序咋不能运行啊。他看了一下，帮我又编辑（其实没有修改一个字符，全都是排列组合的操作）了一番，然后就运行成功了。我当时就佩服得五体投地。这也让我开始不迷信书籍。事实证明，所有的示例代码都是有一定的前提假设才是正确的 所有的示例代码都是有一定的前提假设才是正确的 所有的示例代码都是有一定的前提假设才是正确的自此发奋学习C语言。第一件事当然就是回到自己的电脑上把VC6.0给装了。这个应该来说是很多人学习C语言的第一步，但是却难倒了很多人。因为VC6.0是一款很老的软件，在当前主流的操作系统win7,win8.1（那时候win10还没正式出来）里面不能不经修改地正常运行。这是一个兼容性问题。但是网上的解决办法也很多。因为有之前在网吧搜资源下载的经历，我肯定直接百度，百度经验第一篇就成功帮我解决了这个问题。VC6.0顺利地跑在了我的win8.1上。 然后就是看书，但是因为前车之鉴，我并没有把书上的代码敲一遍跑一下试试。不过我花了两周时间（上课也看）把教科书的前面大部分看完了。这之后老师开始每周布置编程题作业。我其实也并不会做那些题目。代码都是靠百度。不过能顺利把作业交了不就好了么。当时很多人连百度都没用上，直接把别人的作业改个名字就交了。大概又过了两三周，把教科书看完了。之后就没学了。平常作业就是百度一下，然后缝缝补补。这时听了个讲座，有个学长说他一个寒假自学了C++，觉得C++真的好有用。我学了C还没觉得C多有用，所以这时候我就跑去学习C++。当时也是机缘巧合，正好混了个工作室，在工作室里面玩的时候看到里面有一本C++的大部头书，老外写的，中国人翻译的。就借来看。大概看了个把月，把大部分看完了。又过了快一个月，全部看完了。这回我把书上的示例代码都敲过一遍。有的可以运行，也有的有点问题。但是我都没管。把书看完了就行了。前面没有说的一点就是，我上过四次C语言课之后，大家都觉得老师讲得太水了，就不去上课了。上机课也太水了，其实是让我们做编程作业的。但是大家都是百度，去机房和在宿舍没啥区别，所以后来也就不去上机了。 关于读书那么我是怎么在短时间内读完C和C++的书呢？简单总结就是： 不求甚解 自以为是 换位思考 这个总结太简洁了，所以下面还是展开来说。 不求甚解这个应该很好懂。因为C语言的教科书实在是晦涩难懂，这其中犹以某些国内教材为甚。相比之下，国外教材更加通俗易懂，深入浅出。但是老外的思维方式和观念和我们不太一样。说直白点就是人家的思维更加现代化，虽然没吃过猪肉，但是见过猪跑。这时候人家再来学吃猪肉，就知道哪个是前腿子肉，哪个是后腿子肉了不是。 那么到底啥是不求甚解？现阶段我能说的就是，这个C语言也是一门语言，和英语汉语没有什么根本的不一样，没有那么多为什么，不要问那么多为什么。都是极少数语言天才和一群优秀的语言大师约定俗成的。 自以为是这个本来是个贬义词。但我用来表达一个概念就是，C语言里面有些 数据结构 和 算法，有点抽象。抽象最考验人的智商了对不。所以这个时候就需要自以为是了。是不是真的你想的那样其实不重要，重要的是你根据书中的描述或者别人的正确的描述，在你自己的脑海中自以为是起来。 换位思考前面说C语言也是一门语言，语言是用来交流的，只不过C语言是人与计算机交流，普通语言是人与人之间交流。注意，我说的是人与计算机交流，而不是计算机与计算机交流。这个概念我认为很重要。因为只有这样，对人来说，C语言才具有它的可读性。可读性可读性可读性可读性可读性可读性可读性可读性可读性可读性可读性可读性可读性可读性可读性重要的事情可不能只是说三遍。可读性是对人这一方面强调的。这个有点像你自己说的话除了让别人能听懂以外，你自己也得能听懂吧。那计算机呢？众所周知，计算机处理的只是0和1。众所周知，计算机处理的只是0和1。众所周知，计算机处理的只是0和1。众所周知，计算机处理的只是0和1。众所周知，计算机处理的只是0和1。重要的事情还是得多说几遍。计算机的世界就是0和1的世界。计算机的世界就是0和1的世界。计算机的世界就是0和1的世界。计算机的世界就是0和1的世界。计算机的世界就是0和1的世界。前辈们在0和1的基础上设计了很多相对而言简单易懂易用的概念，这个是必须要了解的（深刻理解就有点强人所难了）。注意这里说的是相对而言。所以你要换位思考，计算机的思维方式是怎样的。计算机的时间很单纯，没有人间那么多的弯弯绕绕。对就是对，错就是错，没有模糊选项，只有可选项。 Begin and End前面的About都是一大堆写给自己看的废话。现在正式开始吧。我列个学习计划提纲大概如下： BEGIN0、学习使用搜索引擎。你一定注意到了，这个序号是0。你一定在想为什么，哈哈。这是极有趣的一个预演。因为在编程的世界，表示第一个的序号不是1，而是0。关于搜索引擎，这个非常非常重要。建议使用Google。鉴于国内Google被墙，可以考虑翻墙，或者使用国内某些网站提供的谷歌镜像。（这里肯定有你听不懂的，是时候使用搜索引擎了）这里推荐两个提供镜像的网址：（很稳定） 除了Google之外，必应也还不错。必应的网址是:。微软出品。除了必应以外，百度吧。你不知道，百度一下。除了百度以外，还是算了吧。搜索引擎的使用也有一定的方法，在知乎上看到过很好的回答。这里就不赘述了（反正说得也没人家好）。关于搜索引擎能干嘛，重要性有多大。我就不吹牛逼了。因为我吹得再大也没有实际的大。 1、提前熟悉计算机、编程方面的常用词语、术语、概念、说法。免得后面像刘姥姥进了大观园一样一脸傻逼样。熟悉的方法没别的，去网上的跟C语言、编程、计算机、科技、通信有关的网站、论坛、贴吧之类的，随便逛逛，一定能找到很多不熟悉的说法，然后百度一下。在之后的学习中也是一样的，看到某个说法觉得陌生，就百度一下。噢，这个包括相应的英文版本，并且以英文说法为主要参考。 2、搭建开发环境。注意了啊，我已经开始使用这方面的用语了。所谓搭建开发环境呢，用你能理解的说法就是**在你的电脑（Computer)的操作系统(Operating System)上安装微软公司（Microsoft Corporation)的VC6.0。这个软件貌似在微软官网不太能找到了，现实生产环境中也没人用，但是没关系。中国的教育阵线力量是很强大的，考试用的是这个软件，网上一搜就有一大把，还附带安装说明。 搭建之后熟悉这个软件的菜单位置、基本操作。 3、准备入门书籍。当然大部分学习还是要靠现成的教材的。对初学者来说，一本书就已经够了。但是我的入门教材就是学校的教科书，还是特别老又没有名气的那种。所以也不知道哪本最好。不过很有名气的有两本，国内一个是谭浩强的C语言（这个好像还有视频可以在网上下载到），国外一个是那本最经典的啥啥啥，名字忘了但是就是两个C语言创始人之一编写的那本。国外还有一个专业的计算机类书籍出版社叫O’Reily，凡是这个出版社的书籍，基本上可以说是世界上最顶尖的水平，这个水平包括了很强的可读性、权威性、正确性。（国内很多教材都是敷衍了事出版的，而且作者在写书方面能力匮乏，错误很多，又不好懂）怎么准备呢？使用搜索引擎下载电子档（一般来说就是pdf格式的）；书店买书；图书馆借书；同学借书。（如果有教材的话，一本教材就够了）另外推荐一个小甲鱼C语言教学视频。这个讲师讲得还算有趣，可以试着看几集，看自己是否有兴趣。哦，忘了一本书了，叫嗨翻C语言，老外写的。听名字就知道了，图文并茂，有声有色。这本我只翻过，没有看过，但是应该还行。如果有在图书馆看到这本书，可以试试。 4、一边看示例程序，一边看书。这里我想表达的重点在这里。我最中意的方法就是，带有特定目的（最经典的例如从1加到100）的一段小程序，争取读懂。而且是要没看过书的也要争取读懂。因为前面说过，C语言本身就强调可读性。我会挑选一些程序，详细注释，穿插所涉及的知识点，以供阅读学习。即便没有预习过教材中的有关知识点也没关系。并且我会强调二级考试的重点。 5、看二级考试的参考书。这个书没别的，就一本。专为考试而生。考前借来看看就行了。如果前面第5步做得不错的话，这一步可以省略，或者敷衍了事。注意我说的是前面的第5步，其实序号是4。因为这一部分只占到了考试的10%，又全都是选择题。而且在前面的学习中，已经可以掌握一部分这方面的内容。 6、’\0’C语言中字符串的结束符是这个。 提问第一步，向自己提问；第二步，向教科书提问；第三步，向搜索引擎提问；第四步，向周围的人提问，比如我。 提问要明确自己到底要知道要搞懂的是什么。提问要注意方式方法，遇到什么情况，要说清楚说详细说具体，而且要挑重点挑关键点强调，这样才方便别人解答。举个例子，比较常见的令初学者头疼的就是那个VC6.0报错。提问至少需要提供两方面内容，一个是源代码，一个是报错内容。 END这篇文章大概有两个用处，一个是给我本人自己回顾历史，一个是给要准备二级C语言考试的人消遣。文章中很多没有说明白的，很多说漏的，很多说错的，这在所难免。有些也是我故意略去的，比如学习编程需要很好的英文阅读水平。这点没有强调是因为我觉得对于二级C语言考试来说，这个完全可以忽略。但是有些对二级考试不重要的我又挑出来说了，是因为我觉得这些很重要，在任何场景下。比如使用搜索引擎。老的程序员有个说法，以前说 程序 = 数据结构 + 算法现在是程序 = 搜索引擎 + 英语 这篇文章通篇说得太泛。这不要紧，说具体不是本文的目的。后面我会继续写具体。当然是在另外一些文章里面了，但是同样是发表在这个网站。由于这个网站对文章的管理方式，我决定之后的文章都采用这样的命名方式： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// SetTie.cpp/* 给文章设置一个统一规范的标题。*//* 这个示例程序基本包含了C语言的精华。对正准备入门但还没迈开脚的人来说，读不懂是正常的。但是呢，记得运用前面是三个方法：不求甚解自以为是换位思考。 *//* 哎呀忘了介绍了，这个/* 和 * /是写注释的地方，在这两个符号里面随便写啥都行。我把后面那个中间加了个空格，因为如果不加的话，这个注释就Over了这不是我想看到的。*/// 这个//嘛，也是写注释的地方，但是呢，只能在这一行里面写。#include&lt;stdio.h&gt; // 包含头文件，以使用头文件中的内容。以.h作为文件后缀名。stdio.h是标准(std=standard)输入输出(io=input,output)头文件。#define ARTICLES 20 // 宏定义。对于某些固定的常量，比如我要写的文章总数20，我用一个ARTICLE表示。就是“定义ARTICLE为20”#define STR_LEN 100 //和上面一样，这次定义的是一个字符串长度 int SetTitle();// 函数声明，这里可以不写函数主体。这个函数比较复杂，我也不会写。所以就是简单表示一下含义。int main()// main()是固定的，是整个程序的entry入口。&#123; int i = 0; // 定义一个整型变量（就是整数）i，并赋值(assign)为0。i这个字母通常用来做循环计数，第一次循环，第二次循环…… // 循环头。for后面的括号里面，第一个i=0是初始条件，第二个i&lt;ARTICLE是循环终止判断条件，不满足这个条件的时候循环终止；第三个i++是每次循环的后面都要执行的一个操作，一般就是i++这样的，表示循环次数+1。 for(i=0;l++;i&lt;ARTICLES) SetTitle(&quot;C语言入门奇葩说-%d&quot;,i); //这行代码按标准需要用一个大括号括起来，但是因为只有一行，大括号可以省略。这里是调用了前面声明的那个函数。将我的文章标题设置为《C语言奇葩说-0》、《C语言奇葩说-1》、《C语言奇葩说-2》…… char string[STR_LEN] = &quot;上面那个SetTitle()函数啊，有点像我这个printf()函数呢&quot;; printf(&quot;%s&quot;,string);//这个函数是初学阶段最重要最常用的一个函数，没有之一。作用就是打印（print,是打印显示到输出设备比如屏幕上的）。 return 0; //有没有发现函数名字前面都有一个单词，main()前面是int，就要返回一个int整型数。一般来说，程序正常结束的话就返回一个0，异常就返回-1。&#125;//~the end of main()int SetTitle()//一般来说，这一行就和前面那个声明一模一样，直接复制粘贴就行了&#123; ...//这个函数我是真的不知道怎么写&#125;//~the end of SetTile()//~the end of SetTitle.cpp]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>C语言</tag>
        <tag>入门</tag>
      </tags>
  </entry>
</search>
